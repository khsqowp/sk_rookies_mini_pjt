"""
ë¡œê·¸ ë¶„ì„ ì—”ì§„ v4
- v2ì™€ sim_v3ì˜ ê¸°ëŠ¥ì„ í†µí•©í•œ í‘œì¤€ ë¶„ì„ ì—”ì§„
- ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì•…ì„±ì½”ë“œ íƒì§€
"""
import os
import pandas as pd
import numpy as np
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')


class LogAnalyzer:
    def __init__(self, vector_db_path: str = None, silent: bool = False):
        """
        ë¡œê·¸ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™”

        Args:
            vector_db_path: ë²¡í„° DB ê²½ë¡œ (ê¸°ë³¸ê°’: ./vector_db/faiss_index)
            silent: Trueì¼ ê²½ìš° ì´ˆê¸°í™” ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
        """
        # ê²½ë¡œ ì„¤ì •
        script_dir = os.path.dirname(os.path.abspath(__file__))
        if vector_db_path is None:
            vector_db_path = os.path.join(script_dir, "vector_db", "faiss_index")

        self.db_path = vector_db_path
        self.silent = silent

        if not self.silent:
            print("ğŸ”§ ë¡œê·¸ ë¶„ì„ ì—”ì§„(V4) ì´ˆê¸°í™” ì¤‘...")

        # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        if not self.silent:
            print("  - ì„ë² ë”© ëª¨ë¸ ë¡œë“œ...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name='sentence-transformers/all-MiniLM-L6-v2',
            model_kwargs={'device': 'cpu'}
        )

        # 2. ë²¡í„° DB ë¡œë“œ
        if not self.silent:
            print("  - ë²¡í„° DB ë¡œë“œ...")
        
        if not os.path.exists(self.db_path):
            raise FileNotFoundError(f"ë²¡í„° DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.db_path}. 'vector_db_builder.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

        self.vectordb = FAISS.load_local(
            self.db_path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        if not self.silent:
            print(f"  âœ… {self.vectordb.index.ntotal}ê°œ ë²¡í„° ë¡œë“œ ì™„ë£Œ")
            print("âœ… ë¡œê·¸ ë¶„ì„ ì—”ì§„(V4) ì´ˆê¸°í™” ì™„ë£Œ!\n")

    def preprocess_csv(self, csv_path: str) -> pd.DataFrame:
        """
        CSV íŒŒì¼ ì „ì²˜ë¦¬

        Args:
            csv_path: CSV íŒŒì¼ ê²½ë¡œ

        Returns:
            ì „ì²˜ë¦¬ëœ DataFrame
        """
        if not self.silent:
            print(f"ğŸ“‚ CSV íŒŒì¼ ë¡œë“œ ì¤‘: {os.path.basename(csv_path)}")

        df = pd.read_csv(csv_path)
        
        if not self.silent:
            print(f"  - ì´ {len(df):,}ê°œ í–‰ ë¡œë“œ")
            print(f"  - ì»¬ëŸ¼: {len(df.columns)}ê°œ")

        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(0)

        if not self.silent:
            print(f"  âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
        return df

    def row_to_text(self, row: pd.Series) -> str:
        """
        DataFrameì˜ í•œ í–‰ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            row: DataFrameì˜ í•œ í–‰

        Returns:
            í…ìŠ¤íŠ¸ í˜•ì‹ì˜ í–‰ ë°ì´í„°
        """
        parts = []
        for col, val in row.items():
            if isinstance(val, (int, float, np.integer, np.floating)) and not pd.isna(val):
                parts.append(f"{col}: {val}")

        return ", ".join(parts)

    def analyze_single_row(self, row_text: str, top_k: int = 5) -> Dict:
        """
        ë‹¨ì¼ ë¡œê·¸ í–‰ ë¶„ì„

        Args:
            row_text: í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ëœ ë¡œê·¸ í–‰
            top_k: ê²€ìƒ‰í•  ìœ ì‚¬ ë¬¸ì„œ ê°œìˆ˜

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        docs = self.vectordb.similarity_search_with_score(row_text, k=top_k)

        attack_types = []
        labels = []
        scores = []

        for doc, score in docs:
            metadata = doc.metadata
            attack_types.append(metadata.get('attack_cat', 'Unknown'))
            labels.append(metadata.get('label', 'Unknown'))
            scores.append(float(score))

        best_doc, best_score = docs[0]

        from collections import Counter
        attack_counter = Counter(attack_types)
        most_common_attack = attack_counter.most_common(1)[0][0] if attack_types else "Unknown"

        label_counter = Counter(labels)
        most_common_label = label_counter.most_common(1)[0][0] if labels else "Unknown"

        confidence = 1 / (1 + best_score) if best_score > 0 else 1.0

        # ì†ŒìŠ¤ IPì™€ ëª©ì ì§€ IP ì¶”ì¶œ (ì»¬ëŸ¼ ì´ë¦„ì´ ì¡´ì¬í•  ê²½ìš°)
        src_ip, dst_ip = "N/A", "N/A"
        try:
            parts = row_text.split(", ")
            for part in parts:
                if "Source IP:" in part:
                    src_ip = part.split(":")[1].strip()
                if "Destination IP:" in part:
                    dst_ip = part.split(":")[1].strip()
        except Exception:
            pass # IP ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ

        return {
            'is_malware': most_common_label == 'ì•…ì„±',
            'attack_type': most_common_attack,
            'confidence': confidence,
            'similarity_score': best_score,
            'top_matches': attack_types[:3],
            'match_scores': scores[:3],
            'source_ip': src_ip,
            'destination_ip': dst_ip,
            'log_text': row_text,
        }

    def analyze_csv(self, csv_path: str, top_k: int = 5, sample_size: int = None) -> tuple:
        """
        ì „ì²´ CSV íŒŒì¼ ë¶„ì„

        Args:
            csv_path: CSV íŒŒì¼ ê²½ë¡œ
            top_k: ê° í–‰ë§ˆë‹¤ ê²€ìƒ‰í•  ìœ ì‚¬ ë¬¸ì„œ ê°œìˆ˜
            sample_size: ìƒ˜í”Œë§í•  í–‰ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)

        Returns:
            (ë¶„ì„ ê²°ê³¼ DataFrame, ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        """
        df = self.preprocess_csv(csv_path)

        if sample_size and sample_size < len(df):
            if not self.silent:
                print(f"  âš ï¸  í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ {sample_size}ê°œ í–‰ë§Œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\n")
            df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)

        if not self.silent:
            print(f"ğŸ” {len(df):,}ê°œ ë¡œê·¸ ë¶„ì„ ì¤‘...")

        results = []
        for idx, row in df.iterrows():
            if not self.silent and (idx + 1) % 100 == 0 or idx == 0:
                print(f"  ì§„í–‰: {idx + 1}/{len(df)} ({(idx + 1) / len(df) * 100:.1f}%)")

            row_text = self.row_to_text(row)
            result = self.analyze_single_row(row_text, top_k=top_k)
            results.append(result)

        if not self.silent:
            print(f"  âœ… ë¶„ì„ ì™„ë£Œ!\n")

        df_results = pd.DataFrame(results)
        
        # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
        # ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹˜ë¯€ë¡œ, ìƒ˜í”Œë§ì„ í–ˆë”ë¼ë„ ì¸ë±ìŠ¤ê°€ ë§ì•„ì•¼ í•¨
        df.reset_index(drop=True, inplace=True)
        df_results.reset_index(drop=True, inplace=True)
        
        final_df = pd.concat([df, df_results], axis=1)

        return final_df, results

    def generate_summary(self, df: pd.DataFrame) -> Dict:
        """
        ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±

        Args:
            df: ë¶„ì„ ê²°ê³¼ DataFrame

        Returns:
            ìš”ì•½ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        total_rows = len(df)
        malware_count = df['is_malware'].sum()
        benign_count = total_rows - malware_count

        attack_type_counts = df['attack_type'].value_counts().to_dict()
        avg_confidence = df['confidence'].mean()

        attack_stats = {}
        for attack_type, count in attack_type_counts.items():
            attack_df = df[df['attack_type'] == attack_type]
            attack_stats[attack_type] = {
                'count': count,
                'avg_confidence': attack_df['confidence'].mean(),
                'percentage': count / total_rows * 100 if total_rows > 0 else 0
            }

        summary = {
            'total_logs': total_rows,
            'malware_detected': int(malware_count),
            'benign_detected': int(benign_count),
            'malware_percentage': (malware_count / total_rows * 100) if total_rows > 0 else 0,
            'attack_type_distribution': attack_type_counts,
            'attack_stats': attack_stats,
            'average_confidence': avg_confidence
        }

        return summary
