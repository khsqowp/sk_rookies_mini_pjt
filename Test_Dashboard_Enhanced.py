"""
V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ (Enhanced Version)
- ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ëŒ€ì‹œë³´ë“œ ê°•í™”
- ì‚¬ê³  ëŒ€ì‘ íƒ­ êµ¬í˜„
- ë³´ê³ ì„œ ìë™ ìƒì„± ì‹œìŠ¤í…œ (ì¼ê°„/ì£¼ê°„/ì›”ê°„/ì‚¬ê³ )
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import time
from datetime import datetime, timedelta
import traceback
from pathlib import Path
import json
import queue
import threading
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import openai

# Watchdog ê´€ë ¨ ì„í¬íŠ¸
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸
from ransomware_model import RansomwareModel
from feature_extractor import extract_pe_header_features

# --- 1. í˜ì´ì§€ ë° ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ìºì‹œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent
LOGS_DIR = BASE_DIR / "logs"
REPORTS_DIR = BASE_DIR / "reports"
DOWNLOAD_DIR = Path.home() / "Downloads"
ANALYSIS_EXTENSIONS = {".exe", ".dll"}

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(LOGS_DIR, exist_ok=True)
os.makedirs(REPORTS_DIR / "daily", exist_ok=True)
os.makedirs(REPORTS_DIR / "weekly", exist_ok=True)
os.makedirs(REPORTS_DIR / "monthly", exist_ok=True)
os.makedirs(REPORTS_DIR / "incidents", exist_ok=True)
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# --- 3. AI ìš”ì•½ ê¸°ëŠ¥ ---
@st.cache_data(ttl=300)
def get_ai_summary(analysis_result: dict) -> str:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."

    client = openai.OpenAI(api_key=api_key)

    file_name = analysis_result['file_name']
    result = analysis_result['result']
    label = "ëœì„¬ì›¨ì–´" if result['label'] == 1 else "ì •ìƒ íŒŒì¼"
    prob = result['prob_ransom']
    anomalies = result['anomalies']

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
ë‹¹ì‹ ì€ ìµœê³ ì˜ ì‚¬ì´ë²„ ë³´ì•ˆ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ëœì„¬ì›¨ì–´ íƒì§€ ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ , ë³´ì•ˆ ê´€ì œ ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ìƒí™©ì„ íŒŒì•…í•˜ê³  ì¡°ì¹˜í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ëª…í™•í•œ ê¶Œê³  ì‚¬í•­ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ íŒŒì¼:** `{file_name}`

**[ë¶„ì„ ê²°ê³¼]**
- **íŒì •:** {label}
- **ëœì„¬ì›¨ì–´ì¼ í™•ë¥ :** {prob:.2%}

**[íŒë‹¨ì˜ ì£¼ìš” ê·¼ê±° (ì´ìƒ ì§•í›„ Top 5)]**
"""
    if not anomalies:
        prompt += "- íŠ¹ì´í•œ ì´ìƒ ì§•í›„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
    else:
        for i, anom in enumerate(anomalies[:5], 1):
            prompt += f"- **{i}. {anom['description']} ({anom['feature']})**: ì¸¡ì •ê°’ {anom['value']:.2f} (ì •ìƒ í‰ê· : {anom['mean']:.2f}, Z-Score: {anom['z_score']:.2f})\n"

    prompt += """
---
**[ìš”ì•½ ë° ê¶Œê³ ]** (ì•„ë˜ í˜•ì‹ì— ë§ì¶° í•œê¸€ë¡œ ì‘ì„±)
1. **ìœ„í˜‘ ìš”ì•½:** (ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ íŒŒì¼ì´ ì™œ ìœ„í—˜í•œì§€ ë˜ëŠ” ì•ˆì „í•œì§€ì— ëŒ€í•œ í•µì‹¬ ìš”ì•½)
2. **ì‹ ë¢°ë„ í‰ê°€:** (íƒì§€ í™•ë¥ ê³¼ ì´ìƒ ì§•í›„ë¥¼ ê³ ë ¤í•˜ì—¬, ì´ ë¶„ì„ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€)
3. **ê¶Œê³  ì¡°ì¹˜:** (ë³´ì•ˆ ë‹´ë‹¹ìê°€ ìˆ˜í–‰í•´ì•¼ í•  ë‹¤ìŒ í–‰ë™ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ)
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìµœê³ ì˜ ì‚¬ì´ë²„ ë³´ì•ˆ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- 4. ë¡œê·¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=5)
def load_events_log():
    """ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ì„ ì½ì–´ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    log_file_path = LOGS_DIR / "events.jsonl"
    if not log_file_path.exists() or log_file_path.stat().st_size == 0:
        return pd.DataFrame()

    try:
        log_lines = log_file_path.read_text(encoding="utf-8").strip().split('\n')
        log_rows = [json.loads(line) for line in log_lines if line.strip()]
        df = pd.DataFrame(log_rows)

        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        return df.sort_values('timestamp', ascending=False)
    except Exception as e:
        st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# --- 5. ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ê³„ì‚° ---
def calculate_dashboard_metrics(df):
    """ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    if df.empty:
        return {
            'total_events': 0,
            'ransomware_count': 0,
            'benign_count': 0,
            'ransomware_ratio': 0,
            'recent_1h_count': 0,
            'avg_probability': 0
        }

    total_events = len(df)
    ransomware_count = (df['label'] == 1).sum()
    benign_count = (df['label'] == 0).sum()
    ransomware_ratio = ransomware_count / total_events if total_events > 0 else 0

    # ìµœê·¼ 1ì‹œê°„ ì´ë²¤íŠ¸ ìˆ˜
    one_hour_ago = datetime.now() - timedelta(hours=1)
    recent_1h_count = (df['timestamp'] >= one_hour_ago).sum()

    # í‰ê·  ëœì„¬ì›¨ì–´ í™•ë¥ 
    avg_probability = df['probability'].mean() if 'probability' in df.columns else 0

    return {
        'total_events': total_events,
        'ransomware_count': ransomware_count,
        'benign_count': benign_count,
        'ransomware_ratio': ransomware_ratio,
        'recent_1h_count': recent_1h_count,
        'avg_probability': avg_probability
    }

# --- 6. ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ ---
def create_timeline_chart(df):
    """ì‹œê°„ë³„ íƒì§€ ì¶”ì´ ì°¨íŠ¸"""
    if df.empty:
        return None

    # ì‹œê°„ë³„ ê·¸ë£¹í™”
    df_hourly = df.copy()
    df_hourly['hour'] = df_hourly['timestamp'].dt.floor('H')

    hourly_stats = df_hourly.groupby(['hour', 'label']).size().reset_index(name='count')
    hourly_stats['label_name'] = hourly_stats['label'].map({0: 'ì •ìƒ', 1: 'ëœì„¬ì›¨ì–´'})

    fig = px.line(
        hourly_stats,
        x='hour',
        y='count',
        color='label_name',
        title='ì‹œê°„ë³„ íƒì§€ ì¶”ì´',
        labels={'hour': 'ì‹œê°„', 'count': 'íƒì§€ ìˆ˜', 'label_name': 'ë¶„ë¥˜'},
        color_discrete_map={'ì •ìƒ': '#28a745', 'ëœì„¬ì›¨ì–´': '#dc3545'}
    )

    fig.update_layout(
        xaxis_title='ì‹œê°„',
        yaxis_title='íƒì§€ ìˆ˜',
        hovermode='x unified',
        height=400
    )

    return fig

def create_probability_distribution_chart(df):
    """ëœì„¬ì›¨ì–´ í™•ë¥  ë¶„í¬ ì°¨íŠ¸"""
    if df.empty or 'probability' not in df.columns:
        return None

    fig = px.histogram(
        df,
        x='probability',
        color='label',
        nbins=20,
        title='ëœì„¬ì›¨ì–´ í™•ë¥  ë¶„í¬',
        labels={'probability': 'ëœì„¬ì›¨ì–´ í™•ë¥ ', 'label': 'ë¶„ë¥˜', 'count': 'ë¹ˆë„'},
        color_discrete_map={0: '#28a745', 1: '#dc3545'}
    )

    fig.update_layout(
        xaxis_title='ëœì„¬ì›¨ì–´ í™•ë¥ ',
        yaxis_title='ë¹ˆë„',
        height=400,
        showlegend=True
    )

    return fig

def create_risk_gauge_chart(avg_probability):
    """ìœ„í—˜ë„ ê²Œì´ì§€ ì°¨íŠ¸"""
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=avg_probability * 100,
        title={'text': "í‰ê·  ìœ„í—˜ë„ (%)"},
        delta={'reference': 50},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkred"},
            'steps': [
                {'range': [0, 30], 'color': "#28a745"},
                {'range': [30, 70], 'color': "#ffc107"},
                {'range': [70, 100], 'color': "#dc3545"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))

    fig.update_layout(height=300)
    return fig

# --- 7. ëª¨ë¸ ë¡œë“œ ---
@st.cache_resource
def load_ransomware_model():
    """ëœì„¬ì›¨ì–´ íƒì§€ ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
    try:
        return RansomwareModel()
    except Exception as e:
        st.error(f"âŒ ëœì„¬ì›¨ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.warning("ëª¨ë¸ íŒŒì¼('models/ransom_model.pkl')ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None

# --- 8. Watchdog ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
class WatcherEventHandler(FileSystemEventHandler):
    """íŒŒì¼ ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•˜ì—¬ íì— ë„£ëŠ” í•¸ë“¤ëŸ¬"""
    def __init__(self, file_queue: queue.Queue):
        super().__init__()
        self.file_queue = file_queue

    def on_created(self, event):
        if not event.is_directory:
            self.file_queue.put(Path(event.src_path))

    def on_moved(self, event):
        if not event.is_directory:
            self.file_queue.put(Path(event.dest_path))

def _wait_until_download_complete(path: Path, timeout: float = 10.0):
    """íŒŒì¼ í¬ê¸°ê°€ ë” ì´ìƒ ë³€í•˜ì§€ ì•Šì„ ë•Œê¹Œì§€ ëŒ€ê¸°"""
    last_size = -1
    stable_count = 0
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            current_size = path.stat().st_size
            if current_size > 0 and current_size == last_size:
                stable_count += 1
                if stable_count >= 3:
                    return True
            else:
                stable_count = 0
            last_size = current_size
            time.sleep(0.5)
        except FileNotFoundError:
            time.sleep(0.5)
    return False

def handle_action(file_path: Path, model_result: dict, **kwargs):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "file_name": file_path.name,
        "file_path": str(file_path),
        "label": model_result.get("label"),
        "probability": model_result.get("prob_ransom"),
        "anomalies": model_result.get("anomalies", []),
        "action": "log",
        "action_result": "success"
    }

    log_file = LOGS_DIR / "events.jsonl"
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

    return log_entry

@st.cache_resource
def start_watcher_service():
    """Watchdog ì˜µì €ë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘í•˜ê³  íë¥¼ ë°˜í™˜"""
    file_queue = queue.Queue()
    event_handler = WatcherEventHandler(file_queue)
    observer = Observer()
    observer.schedule(event_handler, str(DOWNLOAD_DIR), recursive=False)

    thread = threading.Thread(target=observer.start, daemon=True)
    thread.start()

    return observer, file_queue

# --- 9. í˜ì´ì§€ 1: ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ---
def render_realtime_soc_dashboard():
    """í˜ì´ì§€ 1: ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ëŒ€ì‹œë³´ë“œ (ê°•í™” ë²„ì „)"""
    st.header("ğŸ“¡ ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ")
    st.markdown("---")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'monitoring_started' not in st.session_state:
        st.session_state.monitoring_started = False
    if 'last_analysis_result' not in st.session_state:
        st.session_state.last_analysis_result = None

    # "ê´€ì œ ì‹œì‘" ë²„íŠ¼
    if not st.session_state.monitoring_started:
        if st.button("â–¶ï¸ ê´€ì œ ì‹œì‘", type="primary", use_container_width=True):
            st.session_state.monitoring_started = True
            st.rerun()
        st.info(f"'{DOWNLOAD_DIR}' í´ë”ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì‹œí•˜ë ¤ë©´ 'ê´€ì œ ì‹œì‘' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
        return

    # --- ê´€ì œ ì‹œì‘ í›„ UI ---
    observer, file_queue = start_watcher_service()

    # ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹œ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆë§Œ í‘œì‹œ
    if 'monitoring_toast_shown' not in st.session_state:
        st.toast(f"ë‹¤ìš´ë¡œë“œ í´ë” ê°ì‹œ ì‹œì‘: {DOWNLOAD_DIR}", icon="ğŸ‘€")
        st.session_state.monitoring_toast_shown = True

    st.success(f"âœ… **ê°ì‹œ ì¤‘:** '{DOWNLOAD_DIR}' í´ë”")

    # --- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ ---
    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë³´ì•ˆ ë©”íŠ¸ë¦­")

    # ë¡œê·¸ ë°ì´í„° ë¡œë“œ
    df = load_events_log()
    metrics = calculate_dashboard_metrics(df)

    # ë©”íŠ¸ë¦­ ì¹´ë“œ (4ê°œ ì»¬ëŸ¼)
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="ì´ íƒì§€ ìˆ˜",
            value=f"{metrics['total_events']}ê±´",
            delta=f"+{metrics['recent_1h_count']}ê±´ (1ì‹œê°„)",
            delta_color="normal"
        )

    with col2:
        st.metric(
            label="ëœì„¬ì›¨ì–´ íƒì§€",
            value=f"{metrics['ransomware_count']}ê±´",
            delta=f"{metrics['ransomware_ratio']:.1%}",
            delta_color="inverse"
        )

    with col3:
        st.metric(
            label="ì •ìƒ íŒŒì¼",
            value=f"{metrics['benign_count']}ê±´",
            delta=f"{(1-metrics['ransomware_ratio']):.1%}",
            delta_color="normal"
        )

    with col4:
        st.metric(
            label="í‰ê·  ìœ„í—˜ë„",
            value=f"{metrics['avg_probability']:.2%}",
            delta="ì‹¤ì‹œê°„",
            delta_color="off"
        )

    st.markdown("---")

    # --- ì°¨íŠ¸ ì‹œê°í™” (2ê°œ ì»¬ëŸ¼) ---
    if not df.empty:
        col1, col2 = st.columns(2)

        with col1:
            timeline_chart = create_timeline_chart(df)
            if timeline_chart:
                st.plotly_chart(timeline_chart, use_container_width=True)

        with col2:
            prob_chart = create_probability_distribution_chart(df)
            if prob_chart:
                st.plotly_chart(prob_chart, use_container_width=True)

        # ìœ„í—˜ë„ ê²Œì´ì§€
        if metrics['avg_probability'] > 0:
            gauge_chart = create_risk_gauge_chart(metrics['avg_probability'])
            st.plotly_chart(gauge_chart, use_container_width=True)

    st.markdown("---")

    # --- íŒŒì¼ í ì²˜ë¦¬ ---
    files_processed = False
    try:
        while True:
            file_path = file_queue.get_nowait()
            files_processed = True

            if file_path.suffix.lower() not in ANALYSIS_EXTENSIONS:
                st.toast(f"ë¶„ì„ ëŒ€ìƒ ì•„ë‹˜ (ë¬´ì‹œ): {file_path.name}", icon="ğŸ¤·")
                continue

            st.toast(f"'{file_path.name}' íŒŒì¼ ë¶„ì„ ì¤‘...", icon="â±ï¸")

            if not _wait_until_download_complete(file_path):
                st.warning(f"'{file_path.name}' íŒŒì¼ì´ ì•ˆì •í™”ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            try:
                # 1. ë¶„ì„ ìˆ˜í–‰
                features = extract_pe_header_features(file_path)
                result = ransomware_model.predict_with_explanation(features)

                analysis_payload = {
                    "file_name": file_path.name,
                    "result": result
                }
                st.session_state.last_analysis_result = analysis_payload

                # 2. ë¡œê·¸ ê¸°ë¡
                handle_action(
                    file_path=file_path,
                    model_result=result
                )

                # 3. AI ìš”ì•½ ìš”ì²­
                st.toast("ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ë¸Œë¦¬í•‘ ìš”ì²­ ì¤‘...", icon="ğŸ§ ")
                summary = get_ai_summary(analysis_payload)
                st.session_state.ai_summary = summary

                # 4. ì™„ë£Œ í›„ í† ìŠ¤íŠ¸ ì˜ˆì•½
                st.session_state.show_analysis_complete_toast = file_path.name

            except Exception as e:
                st.error(f"âŒ '{file_path.name}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
                st.code(traceback.format_exc())

    except queue.Empty:
        pass

    # í•˜ë‚˜ ì´ìƒì˜ íŒŒì¼ì„ ì²˜ë¦¬í–ˆë‹¤ë©´ UIë¥¼ ì¦‰ì‹œ ìƒˆë¡œê³ ì¹¨
    if files_processed:
        st.rerun()

    # --- ìµœì‹  ë¶„ì„ ê²°ê³¼ í‘œì‹œ ---
    if st.session_state.last_analysis_result:
        analysis = st.session_state.last_analysis_result
        result = analysis['result']
        label = result['label']
        prob = result['prob_ransom']
        anomalies = result['anomalies']

        st.subheader(f"ğŸ“œ ìµœì‹  ë¶„ì„ ê²°ê³¼: '{analysis['file_name']}'")

        # AI ìš”ì•½ í‘œì‹œ
        if st.session_state.get("ai_summary"):
            with st.expander("ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ë¸Œë¦¬í•‘ ë³´ê¸°", expanded=True):
                st.markdown(st.session_state.ai_summary)

        if label == 1:
            st.error(f"**ğŸš¨ ëœì„¬ì›¨ì–´ ì˜ì‹¬ (í™•ë¥ : {prob:.2%})**")
        else:
            st.success(f"**âœ… ì •ìƒ íŒŒì¼ë¡œ íŒë‹¨ (ëœì„¬ì›¨ì–´ í™•ë¥ : {prob:.2%})**")

        if anomalies:
            st.warning("ì£¼ìš” ì´ìƒ ì§•í›„:")
            for anom in anomalies[:5]:
                st.markdown(f"- **{anom['description']}** (`{anom['feature']}`: `{anom['value']:.2f}`)")
        st.markdown("---")

    # --- ì „ì²´ íƒì§€ ë¡œê·¸ í‘œì‹œ ---
    st.subheader("ğŸ“‚ ì „ì²´ íƒì§€ ë¡œê·¸")
    if not df.empty:
        # ìµœê·¼ 20ê°œë§Œ í‘œì‹œ
        st.dataframe(
            df.head(20)[['timestamp', 'file_name', 'label', 'probability', 'action_result']],
            use_container_width=True
        )
    else:
        st.info("ì•„ì§ ê¸°ë¡ëœ íƒì§€ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 1ì´ˆë§ˆë‹¤ UIë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ íë¥¼ ê³„ì† í™•ì¸
    time.sleep(1)
    st.rerun()

# --- 10. ì‚¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ ---
INCIDENTS_FILE = LOGS_DIR / "incidents.json"

def load_incidents():
    """ì‚¬ê³  ëª©ë¡ ë¡œë“œ"""
    if not INCIDENTS_FILE.exists():
        return []
    try:
        with open(INCIDENTS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return []

def save_incidents(incidents):
    """ì‚¬ê³  ëª©ë¡ ì €ì¥"""
    with open(INCIDENTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(incidents, f, ensure_ascii=False, indent=2)

def create_incident_from_detection(log_entry):
    """íƒì§€ ë¡œê·¸ë¡œë¶€í„° ì‚¬ê³  ìƒì„±"""
    incident = {
        "incident_id": f"INC-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
        "created_at": datetime.now().isoformat(),
        "file_name": log_entry.get("file_name"),
        "file_path": log_entry.get("file_path"),
        "probability": log_entry.get("probability", 0),
        "status": "íƒì§€ë¨",  # íƒì§€ë¨ â†’ ë¶„ì„ì¤‘ â†’ ê²©ë¦¬ë¨ â†’ ë³µêµ¬ì¤‘ â†’ ì™„ë£Œ
        "priority": "ë†’ìŒ" if log_entry.get("probability", 0) > 0.7 else "ì¤‘ê°„",
        "assigned_to": "ë¯¸ì§€ì •",
        "timeline": [
            {
                "timestamp": datetime.now().isoformat(),
                "status": "íƒì§€ë¨",
                "description": f"ëœì„¬ì›¨ì–´ íƒì§€ (í™•ë¥ : {log_entry.get('probability', 0):.2%})"
            }
        ],
        "checklist": [
            {"task": "ì´ˆê¸° ë¶„ì„ ì™„ë£Œ", "completed": False},
            {"task": "ì˜í–¥ ë²”ìœ„ íŒŒì•…", "completed": False},
            {"task": "íŒŒì¼ ê²©ë¦¬/ì‚­ì œ", "completed": False},
            {"task": "ì‹œìŠ¤í…œ ìŠ¤ìº” ì‹¤ì‹œ", "completed": False},
            {"task": "ë°±ì—… ë³µêµ¬ í™•ì¸", "completed": False},
            {"task": "ì‚¬ê³  ë³´ê³ ì„œ ì‘ì„±", "completed": False}
        ],
        "notes": []
    }
    return incident

def update_incident_status(incident_id, new_status, description=""):
    """ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸"""
    incidents = load_incidents()
    for inc in incidents:
        if inc["incident_id"] == incident_id:
            inc["status"] = new_status
            inc["timeline"].append({
                "timestamp": datetime.now().isoformat(),
                "status": new_status,
                "description": description or f"ìƒíƒœ ë³€ê²½: {new_status}"
            })
            break
    save_incidents(incidents)

# --- 11. í˜ì´ì§€ 2: ì‚¬ê³  ëŒ€ì‘ ---
def render_incident_response():
    """í˜ì´ì§€ 2: ì‚¬ê³  ëŒ€ì‘"""
    st.header("ğŸš¨ ì‚¬ê³  ëŒ€ì‘")
    st.markdown("---")

    # ëœì„¬ì›¨ì–´ íƒì§€ ì´ë²¤íŠ¸ë¥¼ ì‚¬ê³ ë¡œ ìë™ ë“±ë¡
    df = load_events_log()
    if not df.empty:
        ransomware_events = df[df['label'] == 1]

        # ê¸°ì¡´ ì‚¬ê³  ëª©ë¡ ë¡œë“œ
        incidents = load_incidents()
        existing_files = {inc['file_name'] for inc in incidents}

        # ìƒˆë¡œìš´ ëœì„¬ì›¨ì–´ íƒì§€ë¥¼ ì‚¬ê³ ë¡œ ë“±ë¡
        for _, row in ransomware_events.iterrows():
            if row['file_name'] not in existing_files:
                new_incident = create_incident_from_detection(row.to_dict())
                incidents.append(new_incident)

        save_incidents(incidents)

    # ì‚¬ê³  ëª©ë¡ ì¬ë¡œë“œ
    incidents = load_incidents()

    # ì‚¬ê³  í˜„í™© ë©”íŠ¸ë¦­
    st.subheader("ğŸ“Š ì‚¬ê³  ëŒ€ì‘ í˜„í™©")

    active_incidents = [inc for inc in incidents if inc['status'] != 'ì™„ë£Œ']
    completed_incidents = [inc for inc in incidents if inc['status'] == 'ì™„ë£Œ']
    high_priority = [inc for inc in active_incidents if inc['priority'] == 'ë†’ìŒ']

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì‚¬ê³ ", len(incidents))
    with col2:
        st.metric("ì§„í–‰ì¤‘", len(active_incidents), delta=f"-{len(completed_incidents)} ì™„ë£Œ")
    with col3:
        st.metric("ë†’ì€ ìš°ì„ ìˆœìœ„", len(high_priority), delta_color="inverse")
    with col4:
        completion_rate = (len(completed_incidents) / len(incidents) * 100) if incidents else 0
        st.metric("ì™„ë£Œìœ¨", f"{completion_rate:.1f}%")

    st.markdown("---")

    # ì§„í–‰ì¤‘ì¸ ì‚¬ê³  ëª©ë¡
    if active_incidents:
        st.subheader("ğŸ”¥ ì§„í–‰ì¤‘ì¸ ì‚¬ê³ ")

        for inc in active_incidents:
            with st.expander(f"**{inc['incident_id']}** - {inc['file_name']} ({inc['status']})", expanded=False):
                col1, col2 = st.columns([2, 1])

                with col1:
                    st.markdown(f"**íŒŒì¼ëª…:** `{inc['file_name']}`")
                    st.markdown(f"**ê²½ë¡œ:** `{inc['file_path']}`")
                    st.markdown(f"**íƒì§€ í™•ë¥ :** {inc['probability']:.2%}")
                    st.markdown(f"**ìƒì„± ì‹œê°„:** {inc['created_at']}")

                with col2:
                    # ìš°ì„ ìˆœìœ„ ë°°ì§€
                    priority_color = {"ë†’ìŒ": "ğŸ”´", "ì¤‘ê°„": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}
                    st.markdown(f"**ìš°ì„ ìˆœìœ„:** {priority_color.get(inc['priority'], '')} {inc['priority']}")
                    st.markdown(f"**ë‹´ë‹¹ì:** {inc['assigned_to']}")
                    st.markdown(f"**í˜„ì¬ ìƒíƒœ:** **{inc['status']}**")

                st.markdown("---")

                # íƒ€ì„ë¼ì¸
                st.markdown("**ğŸ“… ì‚¬ê³  íƒ€ì„ë¼ì¸:**")
                for event in reversed(inc['timeline']):
                    timestamp = datetime.fromisoformat(event['timestamp']).strftime('%Y-%m-%d %H:%M:%S')
                    st.markdown(f"- **{timestamp}** - {event['status']}: {event['description']}")

                st.markdown("---")

                # ì²´í¬ë¦¬ìŠ¤íŠ¸
                st.markdown("**âœ… ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸:**")
                for i, task in enumerate(inc['checklist']):
                    checked = "â˜‘ï¸" if task['completed'] else "â¬œ"
                    st.markdown(f"{checked} {task['task']}")

                st.markdown("---")

                # ìƒíƒœ ì—…ë°ì´íŠ¸
                st.markdown("**ğŸ”„ ìƒíƒœ ì—…ë°ì´íŠ¸:**")
                col1, col2, col3 = st.columns(3)

                with col1:
                    if st.button("ë¶„ì„ì¤‘ìœ¼ë¡œ ë³€ê²½", key=f"analyze_{inc['incident_id']}"):
                        update_incident_status(inc['incident_id'], "ë¶„ì„ì¤‘", "ë‹´ë‹¹ìê°€ ìƒì„¸ ë¶„ì„ ì‹œì‘")
                        st.rerun()

                with col2:
                    if st.button("ê²©ë¦¬ë¨ìœ¼ë¡œ ë³€ê²½", key=f"isolate_{inc['incident_id']}"):
                        update_incident_status(inc['incident_id'], "ê²©ë¦¬ë¨", "ì•…ì„± íŒŒì¼ ê²©ë¦¬ ì™„ë£Œ")
                        st.rerun()

                with col3:
                    if st.button("ì™„ë£Œë¡œ ë³€ê²½", key=f"complete_{inc['incident_id']}"):
                        update_incident_status(inc['incident_id'], "ì™„ë£Œ", "ì‚¬ê³  ëŒ€ì‘ ì™„ë£Œ")
                        st.rerun()

        st.markdown("---")
    else:
        st.info("í˜„ì¬ ì§„í–‰ì¤‘ì¸ ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì™„ë£Œëœ ì‚¬ê³  ëª©ë¡
    if completed_incidents:
        st.subheader("âœ… ì™„ë£Œëœ ì‚¬ê³ ")

        completed_df = pd.DataFrame([
            {
                "ì‚¬ê³  ID": inc['incident_id'],
                "íŒŒì¼ëª…": inc['file_name'],
                "ìƒì„± ì‹œê°„": inc['created_at'],
                "ì™„ë£Œ ì‹œê°„": inc['timeline'][-1]['timestamp'] if inc['timeline'] else "-",
                "ìš°ì„ ìˆœìœ„": inc['priority']
            }
            for inc in completed_incidents
        ])

        st.dataframe(completed_df, use_container_width=True)
    else:
        st.info("ì•„ì§ ì™„ë£Œëœ ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 12. ë³´ê³ ì„œ ìƒì„± ì‹œìŠ¤í…œ ---
def generate_daily_report(target_date=None):
    """ì¼ê°„ ë³´ê³ ì„œ ìƒì„±"""
    if target_date is None:
        target_date = datetime.now().date()
    else:
        target_date = datetime.fromisoformat(target_date).date() if isinstance(target_date, str) else target_date

    date_str = target_date.strftime('%Y-%m-%d')
    report_dir = REPORTS_DIR / "daily" / date_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['date'] = df['timestamp'].dt.date
    daily_df = df[df['date'] == target_date]

    if daily_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(daily_df)
    ransomware_count = (daily_df['label'] == 1).sum()
    benign_count = (daily_df['label'] == 0).sum()
    avg_prob = daily_df['probability'].mean() if 'probability' in daily_df.columns else 0

    # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
    report_content = f"""# ì¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ë‚ ì§œ:** {date_str}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ìš”ì•½

- **ì´ íƒì§€ ì´ë²¤íŠ¸:** {total_events}ê±´
- **ëœì„¬ì›¨ì–´ íƒì§€:** {ransomware_count}ê±´
- **ì •ìƒ íŒŒì¼:** {benign_count}ê±´
- **í‰ê·  ìœ„í—˜ë„:** {avg_prob:.2%}

---

## 2. ìƒì„¸ í†µê³„

### ì‹œê°„ëŒ€ë³„ íƒì§€ ë¶„í¬
"""

    # ì‹œê°„ëŒ€ë³„ í†µê³„
    hourly_stats = daily_df.groupby(daily_df['timestamp'].dt.hour).size()
    for hour, count in hourly_stats.items():
        report_content += f"- {hour:02d}:00 ~ {hour:02d}:59: {count}ê±´\n"

    report_content += "\n---\n\n## 3. ëœì„¬ì›¨ì–´ íƒì§€ ìƒì„¸\n\n"

    if ransomware_count > 0:
        ransomware_events = daily_df[daily_df['label'] == 1]
        for idx, row in ransomware_events.iterrows():
            report_content += f"""### {row['file_name']}
- **ê²½ë¡œ:** `{row['file_path']}`
- **íƒì§€ ì‹œê°„:** {row['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}
- **ëœì„¬ì›¨ì–´ í™•ë¥ :** {row.get('probability', 0):.2%}
- **ì¡°ì¹˜:** {row.get('action_result', 'N/A')}

"""
    else:
        report_content += "ê¸ˆì¼ ëœì„¬ì›¨ì–´ íƒì§€ ì—†ìŒ\n\n"

    report_content += "\n---\n\n## 4. ê¶Œê³  ì‚¬í•­\n\n"

    if ransomware_count > 0:
        report_content += f"- ê¸ˆì¼ {ransomware_count}ê±´ì˜ ëœì„¬ì›¨ì–´ ì˜ì‹¬ íŒŒì¼ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        report_content += "- ëª¨ë“  ì‹œìŠ¤í…œì— ëŒ€í•œ ì „ì²´ ìŠ¤ìº”ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
        report_content += "- ë°±ì—… ì‹œìŠ¤í…œì˜ ë¬´ê²°ì„±ì„ í™•ì¸í•˜ì„¸ìš”.\n"
    else:
        report_content += "- ê¸ˆì¼ ëœì„¬ì›¨ì–´ íƒì§€ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.\n"
        report_content += "- ì •ê¸°ì ì¸ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”.\n"

    report_content += "\n---\n\n**ë³´ê³ ì„œ ì¢…ë£Œ**"

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"daily_report_{date_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_weekly_report(target_week=None):
    """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±"""
    if target_week is None:
        today = datetime.now()
        week_num = today.isocalendar()[1]
        year = today.year
    else:
        year, week_num = map(int, target_week.split('-W'))

    week_str = f"{year}-W{week_num:02d}"
    report_dir = REPORTS_DIR / "weekly" / week_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ì£¼ì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['week'] = df['timestamp'].dt.isocalendar().week
    df['year'] = df['timestamp'].dt.year
    weekly_df = df[(df['year'] == year) & (df['week'] == week_num)]

    if weekly_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(weekly_df)
    ransomware_count = (weekly_df['label'] == 1).sum()
    benign_count = (weekly_df['label'] == 0).sum()
    avg_prob = weekly_df['probability'].mean() if 'probability' in weekly_df.columns else 0

    # ì¼ë³„ í†µê³„
    daily_stats = weekly_df.groupby(weekly_df['timestamp'].dt.date).agg({
        'label': ['count', lambda x: (x == 1).sum()]
    })

    # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
    report_content = f"""# ì£¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {week_str} ({year}ë…„ {week_num}ì£¼ì°¨)
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ì£¼ê°„ ìš”ì•½

- **ì´ íƒì§€ ì´ë²¤íŠ¸:** {total_events}ê±´
- **ëœì„¬ì›¨ì–´ íƒì§€:** {ransomware_count}ê±´
- **ì •ìƒ íŒŒì¼:** {benign_count}ê±´
- **í‰ê·  ìœ„í—˜ë„:** {avg_prob:.2%}
- **ì¼í‰ê·  íƒì§€:** {total_events / 7:.1f}ê±´

---

## 2. ì¼ë³„ ì¶”ì´

| ë‚ ì§œ | ì´ íƒì§€ | ëœì„¬ì›¨ì–´ | ì •ìƒ |
|------|---------|----------|------|
"""

    for date_val, row in daily_stats.iterrows():
        total = row[('label', 'count')]
        ransomware = row[('label', '<lambda>')]
        benign = total - ransomware
        report_content += f"| {date_val} | {total} | {ransomware} | {benign} |\n"

    report_content += "\n---\n\n## 3. ì£¼ìš” ìœ„í˜‘ ë¶„ì„\n\n"

    if ransomware_count > 0:
        ransomware_events = weekly_df[weekly_df['label'] == 1]
        file_counts = ransomware_events['file_name'].value_counts()
        report_content += "### ê°€ì¥ ë§ì´ íƒì§€ëœ íŒŒì¼ Top 5\n\n"
        for file_name, count in file_counts.head(5).items():
            report_content += f"- **{file_name}**: {count}ê±´\n"
    else:
        report_content += "ì£¼ê°„ ëœì„¬ì›¨ì–´ íƒì§€ ì—†ìŒ\n"

    report_content += "\n---\n\n## 4. ì£¼ê°„ ê¶Œê³  ì‚¬í•­\n\n"

    if ransomware_count > 5:
        report_content += f"- ì´ë²ˆ ì£¼ {ransomware_count}ê±´ì˜ ëœì„¬ì›¨ì–´ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë³´ì•ˆ ì •ì±… ê°•í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
    elif ransomware_count > 0:
        report_content += f"- ì´ë²ˆ ì£¼ {ransomware_count}ê±´ì˜ ëœì„¬ì›¨ì–´ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
    else:
        report_content += "- ì´ë²ˆ ì£¼ ëœì„¬ì›¨ì–´ íƒì§€ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤. ìš°ìˆ˜í•œ ë³´ì•ˆ ìƒíƒœì…ë‹ˆë‹¤.\n"

    report_content += "\n---\n\n**ë³´ê³ ì„œ ì¢…ë£Œ**"

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"weekly_report_{week_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_monthly_report(target_month=None):
    """ì›”ê°„ ë³´ê³ ì„œ ìƒì„±"""
    if target_month is None:
        today = datetime.now()
        year = today.year
        month = today.month
    else:
        year, month = map(int, target_month.split('-'))

    month_str = f"{year}-{month:02d}"
    report_dir = REPORTS_DIR / "monthly" / month_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ì›”ì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['month'] = df['timestamp'].dt.to_period('M')
    target_period = pd.Period(f"{year}-{month:02d}", freq='M')
    monthly_df = df[df['month'] == target_period]

    if monthly_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(monthly_df)
    ransomware_count = (monthly_df['label'] == 1).sum()
    benign_count = (monthly_df['label'] == 0).sum()
    avg_prob = monthly_df['probability'].mean() if 'probability' in monthly_df.columns else 0

    # ì£¼ë³„ í†µê³„
    weekly_stats = monthly_df.groupby(monthly_df['timestamp'].dt.isocalendar().week).agg({
        'label': ['count', lambda x: (x == 1).sum()]
    })

    # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
    report_content = f"""# ì›”ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {month_str} ({year}ë…„ {month}ì›”)
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ì›”ê°„ ìš”ì•½

- **ì´ íƒì§€ ì´ë²¤íŠ¸:** {total_events}ê±´
- **ëœì„¬ì›¨ì–´ íƒì§€:** {ransomware_count}ê±´
- **ì •ìƒ íŒŒì¼:** {benign_count}ê±´
- **í‰ê·  ìœ„í—˜ë„:** {avg_prob:.2%}
- **ì¼í‰ê·  íƒì§€:** {total_events / 30:.1f}ê±´

---

## 2. ì£¼ë³„ ì¶”ì´

| ì£¼ì°¨ | ì´ íƒì§€ | ëœì„¬ì›¨ì–´ | ì •ìƒ |
|------|---------|----------|------|
"""

    for week, row in weekly_stats.iterrows():
        total = row[('label', 'count')]
        ransomware = row[('label', '<lambda>')]
        benign = total - ransomware
        report_content += f"| {week}ì£¼ì°¨ | {total} | {ransomware} | {benign} |\n"

    report_content += "\n---\n\n## 3. ì›”ê°„ ìœ„í˜‘ ë¶„ì„\n\n"

    if ransomware_count > 0:
        ransomware_events = monthly_df[monthly_df['label'] == 1]
        file_counts = ransomware_events['file_name'].value_counts()
        report_content += "### ê°€ì¥ ë§ì´ íƒì§€ëœ íŒŒì¼ Top 10\n\n"
        for file_name, count in file_counts.head(10).items():
            report_content += f"- **{file_name}**: {count}ê±´\n"

        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        hourly_distribution = ransomware_events.groupby(ransomware_events['timestamp'].dt.hour).size()
        peak_hour = hourly_distribution.idxmax()
        report_content += f"\n### íƒì§€ í”¼í¬ ì‹œê°„ëŒ€\n\n- **{peak_hour:02d}:00 ~ {peak_hour:02d}:59**: ê°€ì¥ ë§ì€ íƒì§€ ë°œìƒ\n"
    else:
        report_content += "ì›”ê°„ ëœì„¬ì›¨ì–´ íƒì§€ ì—†ìŒ\n"

    report_content += "\n---\n\n## 4. ì›”ê°„ ê¶Œê³  ì‚¬í•­\n\n"

    if ransomware_count > 10:
        report_content += f"- ì´ë²ˆ ë‹¬ {ransomware_count}ê±´ì˜ ëœì„¬ì›¨ì–´ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë³´ì•ˆ êµìœ¡ ë° ì •ì±… ê°•í™”ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤.\n"
    elif ransomware_count > 0:
        report_content += f"- ì´ë²ˆ ë‹¬ {ransomware_count}ê±´ì˜ ëœì„¬ì›¨ì–´ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ë³´ì•ˆ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ì„¸ìš”.\n"
    else:
        report_content += "- ì´ë²ˆ ë‹¬ ëœì„¬ì›¨ì–´ íƒì§€ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤. ìš°ìˆ˜í•œ ë³´ì•ˆ ê´€ë¦¬ ìƒíƒœì…ë‹ˆë‹¤.\n"

    report_content += "\n---\n\n**ë³´ê³ ì„œ ì¢…ë£Œ**"

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"monthly_report_{month_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_incident_report(incident):
    """ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±"""
    incident_id = incident['incident_id']
    file_name_safe = incident['file_name'].replace('/', '_').replace('\\', '_')
    report_dir = REPORTS_DIR / "incidents" / f"{incident_id}_{file_name_safe}"
    os.makedirs(report_dir, exist_ok=True)

    # ë³´ê³ ì„œ ë‚´ìš© ìƒì„±
    report_content = f"""# ëœì„¬ì›¨ì–´ ì‚¬ê³  ëŒ€ì‘ ë³´ê³ ì„œ
**ì‚¬ê³  ID:** {incident_id}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ì‚¬ê³  ê°œìš”

- **íŒŒì¼ëª…:** `{incident['file_name']}`
- **íŒŒì¼ ê²½ë¡œ:** `{incident['file_path']}`
- **íƒì§€ ì‹œê°„:** {incident['created_at']}
- **ëœì„¬ì›¨ì–´ í™•ë¥ :** {incident['probability']:.2%}
- **ìš°ì„ ìˆœìœ„:** {incident['priority']}
- **ë‹´ë‹¹ì:** {incident['assigned_to']}
- **í˜„ì¬ ìƒíƒœ:** {incident['status']}

---

## 2. ì‚¬ê³  íƒ€ì„ë¼ì¸

"""

    for event in incident['timeline']:
        timestamp = datetime.fromisoformat(event['timestamp']).strftime('%Y-%m-%d %H:%M:%S')
        report_content += f"### {timestamp} - {event['status']}\n{event['description']}\n\n"

    report_content += "---\n\n## 3. ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"

    for task in incident['checklist']:
        status = "âœ… ì™„ë£Œ" if task['completed'] else "â¬œ ë¯¸ì™„ë£Œ"
        report_content += f"- {status}: {task['task']}\n"

    report_content += "\n---\n\n## 4. ì¡°ì¹˜ ì‚¬í•­\n\n"

    if incident['status'] == 'ì™„ë£Œ':
        report_content += "ëª¨ë“  ëŒ€ì‘ ì ˆì°¨ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
    else:
        report_content += f"í˜„ì¬ '{incident['status']}' ìƒíƒœë¡œ ëŒ€ì‘ì´ ì§„í–‰ì¤‘ì…ë‹ˆë‹¤.\n"

    report_content += "\n---\n\n**ë³´ê³ ì„œ ì¢…ë£Œ**"

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / "incident_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    # JSON ìƒì„¸ ë°ì´í„° ì €ì¥
    json_path = report_dir / "analysis_details.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(incident, f, ensure_ascii=False, indent=2)

    return report_path

# --- 13. í˜ì´ì§€ 3: ë³´ê³ ì„œ ì‘ì„± ---
def render_report_generation():
    """í˜ì´ì§€ 3: ë³´ê³ ì„œ ì‘ì„±"""
    st.header("ğŸ“ ë³´ê³ ì„œ ì‘ì„±")
    st.markdown("---")

    st.subheader("ğŸ“… ì •ê¸° ë³´ê³ ì„œ ìƒì„±")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("### ì¼ê°„ ë³´ê³ ì„œ")
        date_input = st.date_input("ë‚ ì§œ ì„ íƒ", value=datetime.now().date())

        if st.button("ì¼ê°„ ë³´ê³ ì„œ ìƒì„±", key="daily_btn"):
            with st.spinner("ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_daily_report(date_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        st.markdown("### ì£¼ê°„ ë³´ê³ ì„œ")
        week_input = st.text_input("ì£¼ì°¨ ì„ íƒ (ì˜ˆ: 2025-W47)", value=f"{datetime.now().year}-W{datetime.now().isocalendar()[1]:02d}")

        if st.button("ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±", key="weekly_btn"):
            with st.spinner("ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_weekly_report(week_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ì£¼ì°¨ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col3:
        st.markdown("### ì›”ê°„ ë³´ê³ ì„œ")
        month_input = st.text_input("ì›” ì„ íƒ (ì˜ˆ: 2025-11)", value=f"{datetime.now().year}-{datetime.now().month:02d}")

        if st.button("ì›”ê°„ ë³´ê³ ì„œ ìƒì„±", key="monthly_btn"):
            with st.spinner("ì›”ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_monthly_report(month_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ì›”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±
    st.subheader("ğŸš¨ ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±")

    incidents = load_incidents()
    if incidents:
        incident_options = {f"{inc['incident_id']} - {inc['file_name']}": inc for inc in incidents}
        selected_incident_key = st.selectbox("ì‚¬ê³  ì„ íƒ", list(incident_options.keys()))

        if st.button("ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±", key="incident_btn"):
            selected_incident = incident_options[selected_incident_key]
            with st.spinner("ì‚¬ê³  ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_incident_report(selected_incident)
                st.success(f"âœ… ì‚¬ê³  ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                st.code(str(report_path))

                # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                with open(report_path, 'r', encoding='utf-8') as f:
                    st.markdown(f.read())
    else:
        st.info("ìƒì„±í•  ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ í‘œì‹œ
    st.subheader("ğŸ“‚ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ êµ¬ì¡°")

    if st.button("ë””ë ‰í† ë¦¬ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    # ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ ìƒì„±
    tree_structure = ""
    for root, dirs, files in os.walk(REPORTS_DIR):
        level = root.replace(str(REPORTS_DIR), '').count(os.sep)
        indent = ' ' * 2 * level
        tree_structure += f"{indent}{os.path.basename(root)}/\n"
        sub_indent = ' ' * 2 * (level + 1)
        for file in files:
            tree_structure += f"{sub_indent}{file}\n"

    st.code(tree_structure, language="")


# --- 12. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
ransomware_model = load_ransomware_model()

if "page" not in st.session_state:
    st.session_state.page = "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ"

with st.sidebar:
    st.title("ğŸ›¡ï¸ V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    page_options = {
        "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ": "ğŸ“¡",
        "ì‚¬ê³  ëŒ€ì‘": "ğŸš¨",
        "ë³´ê³ ì„œ ì‘ì„±": "ğŸ“"
    }

    choice = st.radio(
        "ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(page_options.keys()),
        format_func=lambda x: f"{page_options[x]} {x}"
    )

    if choice != st.session_state.page:
        st.session_state.page = choice
        st.rerun()

    st.markdown("---")
    if ransomware_model:
        st.success("**ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„:** âœ… ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.error("**ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„:** âŒ ë¡œë“œ ì‹¤íŒ¨")
    st.markdown("---")

# í˜ì´ì§€ ë Œë”ë§
if st.session_state.page == "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ":
    if ransomware_model:
        render_realtime_soc_dashboard()
    else:
        st.error("ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì´ í˜ì´ì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
elif st.session_state.page == "ì‚¬ê³  ëŒ€ì‘":
    render_incident_response()
elif st.session_state.page == "ë³´ê³ ì„œ ì‘ì„±":
    render_report_generation()
