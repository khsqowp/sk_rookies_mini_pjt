"""
V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ (Enhanced Version)
- ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ëŒ€ì‹œë³´ë“œ ê°•í™”
- ì‚¬ê³  ëŒ€ì‘ íƒ­ êµ¬í˜„
- ë³´ê³ ì„œ ìë™ ìƒì„± ì‹œìŠ¤í…œ (ì¼ê°„/ì£¼ê°„/ì›”ê°„/ì‚¬ê³ )
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import time
from datetime import datetime, timedelta
import traceback
from pathlib import Path
import json
import queue
import threading
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import openai

# Watchdog ê´€ë ¨ ì„í¬íŠ¸
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸
from ransomware_model import RansomwareModel
from feature_extractor import extract_pe_header_features

# --- 1. í˜ì´ì§€ ë° ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ìºì‹œ ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ ê²½ë¡œ ì„¤ì • ë¡œë“œ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
PROJECT_ROOT = os.getenv("PROJECT_ROOT")
if PROJECT_ROOT:
    BASE_DIR = Path(PROJECT_ROOT)
else:
    BASE_DIR = Path(__file__).resolve().parent

LOGS_DIR = BASE_DIR / "logs"
REPORTS_DIR = BASE_DIR / "reports"
DOWNLOAD_DIR = Path.home() / "Downloads"

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.envì—ì„œ ë¡œë“œ ë˜ëŠ” ê¸°ë³¸ê°’)
MODEL_FILE_PATH = os.getenv("MODEL_PATH")
if MODEL_FILE_PATH:
    MODEL_PATH = Path(MODEL_FILE_PATH)
else:
    MODEL_PATH = BASE_DIR / "best_model_pe.keras"

# í…ŒìŠ¤íŠ¸ íŒŒì¼ ë””ë ‰í† ë¦¬ (.envì—ì„œ ë¡œë“œ ë˜ëŠ” ê¸°ë³¸ê°’)
TEST_FILES_PATH = os.getenv("TEST_FILES_DIR")
if TEST_FILES_PATH:
    TEST_FILES_DIR = Path(TEST_FILES_PATH)
else:
    TEST_FILES_DIR = BASE_DIR / "test_files"

ANALYSIS_EXTENSIONS = {".exe", ".dll"}

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(LOGS_DIR, exist_ok=True)
os.makedirs(REPORTS_DIR / "daily", exist_ok=True)
os.makedirs(REPORTS_DIR / "weekly", exist_ok=True)
os.makedirs(REPORTS_DIR / "monthly", exist_ok=True)
os.makedirs(REPORTS_DIR / "incidents", exist_ok=True)
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# --- 3. AI ìš”ì•½ ê¸°ëŠ¥ ---
@st.cache_data(ttl=300)
def get_ai_summary(analysis_result: dict) -> str:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."

    client = openai.OpenAI(api_key=api_key)

    file_name = analysis_result['file_name']
    result = analysis_result['result']
    label = "ëœì„¬ì›¨ì–´" if result['label'] == 1 else "ì •ìƒ íŒŒì¼"
    prob = result['prob_ransom']
    anomalies = result['anomalies']

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
ë‹¹ì‹ ì€ ìµœê³ ì˜ ì‚¬ì´ë²„ ë³´ì•ˆ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ëœì„¬ì›¨ì–´ íƒì§€ ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ , ë³´ì•ˆ ê´€ì œ ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ìƒí™©ì„ íŒŒì•…í•˜ê³  ì¡°ì¹˜í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ëª…í™•í•œ ê¶Œê³  ì‚¬í•­ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ íŒŒì¼:** `{file_name}`

**[ë¶„ì„ ê²°ê³¼]**
- **íŒì •:** {label}
- **ëœì„¬ì›¨ì–´ì¼ í™•ë¥ :** {prob:.2%}

**[íŒë‹¨ì˜ ì£¼ìš” ê·¼ê±° (ì´ìƒ ì§•í›„ Top 5)]**
"""
    if not anomalies:
        prompt += "- íŠ¹ì´í•œ ì´ìƒ ì§•í›„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
    else:
        for i, anom in enumerate(anomalies[:5], 1):
            prompt += f"- **{i}. {anom['description']} ({anom['feature']})**: ì¸¡ì •ê°’ {anom['value']:.2f} (ì •ìƒ í‰ê· : {anom['mean']:.2f}, Z-Score: {anom['z_score']:.2f})\n"

    prompt += """
---
**[ìš”ì•½ ë° ê¶Œê³ ]** (ì•„ë˜ í˜•ì‹ì— ë§ì¶° í•œê¸€ë¡œ ì‘ì„±)
1. **ìœ„í˜‘ ìš”ì•½:** (ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ íŒŒì¼ì´ ì™œ ìœ„í—˜í•œì§€ ë˜ëŠ” ì•ˆì „í•œì§€ì— ëŒ€í•œ í•µì‹¬ ìš”ì•½)
2. **ì‹ ë¢°ë„ í‰ê°€:** (íƒì§€ í™•ë¥ ê³¼ ì´ìƒ ì§•í›„ë¥¼ ê³ ë ¤í•˜ì—¬, ì´ ë¶„ì„ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€)
3. **ê¶Œê³  ì¡°ì¹˜:** (ë³´ì•ˆ ë‹´ë‹¹ìê°€ ìˆ˜í–‰í•´ì•¼ í•  ë‹¤ìŒ í–‰ë™ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ)
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìµœê³ ì˜ ì‚¬ì´ë²„ ë³´ì•ˆ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- 4. ë¡œê·¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=5)
def load_events_log():
    """ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ì„ ì½ì–´ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    log_file_path = LOGS_DIR / "events.jsonl"
    if not log_file_path.exists() or log_file_path.stat().st_size == 0:
        return pd.DataFrame()

    try:
        log_lines = log_file_path.read_text(encoding="utf-8").strip().split('\n')
        log_rows = []

        for line in log_lines:
            if not line.strip():
                continue
            try:
                row = json.loads(line)

                # í•„ë“œëª… ì •ê·œí™”
                if 'prob_ransom' in row and 'probability' not in row:
                    row['probability'] = row['prob_ransom']
                elif 'probability' not in row:
                    row['probability'] = 0

                # file_name ì¶”ì¶œ (file_pathì—ì„œ) - Windows/Linux ê²½ë¡œ ëª¨ë‘ ì²˜ë¦¬
                if 'file_name' not in row and 'file_path' in row:
                    # Windowsì™€ Linux ê²½ë¡œ ëª¨ë‘ ì²˜ë¦¬
                    file_path = row['file_path']
                    if '\\' in file_path:
                        row['file_name'] = file_path.split('\\')[-1]
                    else:
                        row['file_name'] = file_path.split('/')[-1]
                elif 'file_name' not in row:
                    row['file_name'] = 'unknown'

                # label í•„ë“œ í™•ì¸
                if 'label' not in row:
                    row['label'] = 0

                log_rows.append(row)
            except json.JSONDecodeError as e:
                # ê°œë³„ ë¼ì¸ ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê¸°
                continue

        if not log_rows:
            return pd.DataFrame()

        df = pd.DataFrame(log_rows)

        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ (mixed format ì§€ì›)
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed', utc=True)
            # ë¡œì»¬ íƒ€ì„ì¡´ìœ¼ë¡œ ë³€í™˜
            df['timestamp'] = df['timestamp'].dt.tz_localize(None)

        return df.sort_values('timestamp', ascending=False)
    except Exception as e:
        st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        import traceback
        st.code(traceback.format_exc())
        return pd.DataFrame()

# --- 5. ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ê³„ì‚° ---
def calculate_dashboard_metrics(df):
    """ëŒ€ì‹œë³´ë“œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    if df.empty:
        return {
            'total_events': 0,
            'ransomware_count': 0,
            'benign_count': 0,
            'ransomware_ratio': 0,
            'recent_1h_count': 0,
            'avg_probability': 0
        }

    total_events = len(df)
    ransomware_count = (df['label'] == 1).sum()
    benign_count = (df['label'] == 0).sum()
    ransomware_ratio = ransomware_count / total_events if total_events > 0 else 0

    # ìµœê·¼ 1ì‹œê°„ ì´ë²¤íŠ¸ ìˆ˜
    one_hour_ago = datetime.now() - timedelta(hours=1)
    recent_1h_count = (df['timestamp'] >= one_hour_ago).sum()

    # í‰ê·  ëœì„¬ì›¨ì–´ í™•ë¥ 
    avg_probability = df['probability'].mean() if 'probability' in df.columns else 0

    return {
        'total_events': total_events,
        'ransomware_count': ransomware_count,
        'benign_count': benign_count,
        'ransomware_ratio': ransomware_ratio,
        'recent_1h_count': recent_1h_count,
        'avg_probability': avg_probability
    }

# --- 5-1. ê¸°ê°„ë³„ ë°ì´í„° í•„í„°ë§ í•¨ìˆ˜ ---
def filter_by_period(df, period_type, target_date=None):
    """ê¸°ê°„ë³„ë¡œ ë°ì´í„° í•„í„°ë§"""
    if df.empty:
        return df

    if period_type == 'daily':
        # íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„°ë§Œ
        if target_date is None:
            target_date = datetime.now().date()
        df['date'] = df['timestamp'].dt.date
        return df[df['date'] == target_date]

    elif period_type == 'weekly':
        # íŠ¹ì • ì£¼ì˜ ë°ì´í„°ë§Œ
        if target_date is None:
            target_date = datetime.now()
        week_num = target_date.isocalendar()[1]
        year = target_date.year
        df['week'] = df['timestamp'].dt.isocalendar().week
        df['year'] = df['timestamp'].dt.year
        return df[(df['year'] == year) & (df['week'] == week_num)]

    elif period_type == 'monthly':
        # íŠ¹ì • ì›”ì˜ ë°ì´í„°ë§Œ
        if target_date is None:
            target_date = datetime.now()
        df['month'] = df['timestamp'].dt.to_period('M')
        target_period = pd.Period(f"{target_date.year}-{target_date.month:02d}", freq='M')
        return df[df['month'] == target_period]

    else:  # 'realtime'
        return df

# --- 5-2. ê³µí†µ ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í•¨ìˆ˜ ---
def render_period_dashboard(df, period_name):
    """ê¸°ê°„ë³„ ëŒ€ì‹œë³´ë“œ ê³µí†µ ë Œë”ë§"""
    metrics = calculate_dashboard_metrics(df)

    # ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="ì´ íƒì§€ ìˆ˜",
            value=f"{metrics['total_events']}ê±´",
            delta=f"+{metrics['recent_1h_count']}ê±´ (1ì‹œê°„)" if period_name == "ì‹¤ì‹œê°„" else None
        )

    with col2:
        st.metric(
            label="ëœì„¬ì›¨ì–´ íƒì§€",
            value=f"{metrics['ransomware_count']}ê±´",
            delta=f"{metrics['ransomware_ratio']:.1%}",
            delta_color="inverse"
        )

    with col3:
        st.metric(
            label="ì •ìƒ íŒŒì¼",
            value=f"{metrics['benign_count']}ê±´",
            delta=f"{(1-metrics['ransomware_ratio']):.1%}" if metrics['ransomware_ratio'] < 1 else None
        )

    with col4:
        st.metric(
            label="í‰ê·  ìœ„í—˜ë„",
            value=f"{metrics['avg_probability']:.2%}",
            delta=period_name
        )

    st.markdown("---")

    # ì°¨íŠ¸ ì‹œê°í™”
    if not df.empty:
        col1, col2 = st.columns(2)

        with col1:
            timeline_chart = create_timeline_chart(df)
            if timeline_chart:
                st.plotly_chart(timeline_chart, use_container_width=True, key=f"timeline_{period_name}")

        with col2:
            prob_chart = create_probability_distribution_chart(df)
            if prob_chart:
                st.plotly_chart(prob_chart, use_container_width=True, key=f"prob_{period_name}")

        # ìœ„í—˜ë„ ê²Œì´ì§€
        if metrics['avg_probability'] > 0:
            gauge_chart = create_risk_gauge_chart(metrics['avg_probability'])
            st.plotly_chart(gauge_chart, use_container_width=True, key=f"gauge_{period_name}")

        # ì´ìƒ íŒŒì¼ ëª©ë¡
        ransomware_df = df[df['label'] == 1]
        if not ransomware_df.empty:
            st.markdown("### ğŸš¨ íƒì§€ëœ ì´ìƒ íŒŒì¼ ëª©ë¡")
            st.dataframe(
                ransomware_df[['timestamp', 'file_name', 'probability']].sort_values('probability', ascending=False),
                use_container_width=True,
                key=f"ransom_list_{period_name}"
            )
    else:
        st.info(f"{period_name} ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 6. ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ ---
def create_timeline_chart(df):
    """ì‹œê°„ë³„ íƒì§€ ì¶”ì´ ì°¨íŠ¸"""
    if df.empty:
        return None

    # ì‹œê°„ë³„ ê·¸ë£¹í™”
    df_hourly = df.copy()
    df_hourly['hour'] = df_hourly['timestamp'].dt.floor('H')

    hourly_stats = df_hourly.groupby(['hour', 'label']).size().reset_index(name='count')
    hourly_stats['label_name'] = hourly_stats['label'].map({0: 'ì •ìƒ', 1: 'ëœì„¬ì›¨ì–´'})

    fig = px.line(
        hourly_stats,
        x='hour',
        y='count',
        color='label_name',
        title='ì‹œê°„ë³„ íƒì§€ ì¶”ì´',
        labels={'hour': 'ì‹œê°„', 'count': 'íƒì§€ ìˆ˜', 'label_name': 'ë¶„ë¥˜'},
        color_discrete_map={'ì •ìƒ': '#28a745', 'ëœì„¬ì›¨ì–´': '#dc3545'}
    )

    fig.update_layout(
        xaxis_title='ì‹œê°„',
        yaxis_title='íƒì§€ ìˆ˜',
        hovermode='x unified',
        height=400
    )

    return fig

def create_probability_distribution_chart(df):
    """ëœì„¬ì›¨ì–´ í™•ë¥  ë¶„í¬ ì°¨íŠ¸"""
    if df.empty or 'probability' not in df.columns:
        return None

    fig = px.histogram(
        df,
        x='probability',
        color='label',
        nbins=20,
        title='ëœì„¬ì›¨ì–´ í™•ë¥  ë¶„í¬',
        labels={'probability': 'ëœì„¬ì›¨ì–´ í™•ë¥ ', 'label': 'ë¶„ë¥˜', 'count': 'ë¹ˆë„'},
        color_discrete_map={0: '#28a745', 1: '#dc3545'}
    )

    fig.update_layout(
        xaxis_title='ëœì„¬ì›¨ì–´ í™•ë¥ ',
        yaxis_title='ë¹ˆë„',
        height=400,
        showlegend=True
    )

    return fig

def create_risk_gauge_chart(avg_probability):
    """ìœ„í—˜ë„ ê²Œì´ì§€ ì°¨íŠ¸"""
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=avg_probability * 100,
        title={'text': "í‰ê·  ìœ„í—˜ë„ (%)"},
        delta={'reference': 50},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkred"},
            'steps': [
                {'range': [0, 30], 'color': "#28a745"},
                {'range': [30, 70], 'color': "#ffc107"},
                {'range': [70, 100], 'color': "#dc3545"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))

    fig.update_layout(height=300)
    return fig

# --- 7. ëª¨ë¸ ë¡œë“œ ---
@st.cache_resource
def load_ransomware_model():
    """ëœì„¬ì›¨ì–´ íƒì§€ ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
    try:
        return RansomwareModel()
    except Exception as e:
        st.error(f"âŒ ëœì„¬ì›¨ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.warning("ëª¨ë¸ íŒŒì¼('models/ransom_model.pkl')ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None

# --- 8. Watchdog ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
class WatcherEventHandler(FileSystemEventHandler):
    """íŒŒì¼ ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•˜ì—¬ íì— ë„£ëŠ” í•¸ë“¤ëŸ¬"""
    def __init__(self, file_queue: queue.Queue):
        super().__init__()
        self.file_queue = file_queue

    def on_created(self, event):
        if not event.is_directory:
            self.file_queue.put(Path(event.src_path))

    def on_moved(self, event):
        if not event.is_directory:
            self.file_queue.put(Path(event.dest_path))

def _wait_until_download_complete(path: Path, timeout: float = 10.0):
    """íŒŒì¼ í¬ê¸°ê°€ ë” ì´ìƒ ë³€í•˜ì§€ ì•Šì„ ë•Œê¹Œì§€ ëŒ€ê¸°"""
    last_size = -1
    stable_count = 0
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            current_size = path.stat().st_size
            if current_size > 0 and current_size == last_size:
                stable_count += 1
                if stable_count >= 3:
                    return True
            else:
                stable_count = 0
            last_size = current_size
            time.sleep(0.5)
        except FileNotFoundError:
            time.sleep(0.5)
    return False

def generate_detection_story(file_path: Path, model_result: dict, timestamp: datetime) -> str:
    """íƒì§€ ë¡œê·¸ë¥¼ ìŠ¤í† ë¦¬í…”ë§ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

    # 1. ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸
    hour = timestamp.hour
    day_of_week = timestamp.strftime('%A')
    day_of_week_kr = {
        'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
        'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'
    }.get(day_of_week, day_of_week)

    if 0 <= hour < 6:
        time_context = "ì‹¬ì•¼ ì‹œê°„ëŒ€ (00:00-06:00) - ì •ìƒ ì—…ë¬´ ì‹œê°„ ì™¸"
        time_risk = "âš ï¸ ë¹„ì •ìƒ ì‹œê°„ëŒ€"
    elif 6 <= hour < 9:
        time_context = "ì¶œê·¼ ì‹œê°„ëŒ€ (06:00-09:00) - ì´ë©”ì¼ í™•ì¸ ì‹œê°„"
        time_risk = "ğŸŸ¡ í”¼ì‹± ì£¼ì˜"
    elif 9 <= hour < 18:
        time_context = "ì—…ë¬´ ì‹œê°„ëŒ€ (09:00-18:00) - ì •ìƒ í™œë™ ì‹œê°„"
        time_risk = "âœ… ì •ìƒ ì‹œê°„ëŒ€"
    else:
        time_context = "í‡´ê·¼ í›„ ì‹œê°„ëŒ€ (18:00-24:00) - ê°œì¸ í™œë™"
        time_risk = "ğŸŸ¡ ê·¼ë¬´ ì™¸ ì‹œê°„"

    # 2. íŒŒì¼ í–‰ë™ íŒ¨í„´ ë¶„ì„
    file_name = file_path.name
    file_path_str = str(file_path)

    suspicious_indicators = []

    # íŒŒì¼ëª… ë¶„ì„
    if any(keyword in file_name.lower() for keyword in ['crack', 'keygen', 'patch', 'hack', 'loader']):
        suspicious_indicators.append("âš ï¸ ë¶ˆë²• ì†Œí”„íŠ¸ì›¨ì–´ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨")

    if file_name.count('_') > 3 or (len(file_name) > 5 and sum(c.isdigit() for c in file_name[:5]) >= 3):
        suspicious_indicators.append("âš ï¸ ë¬´ì‘ìœ„ ìƒì„±ëœ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” íŒŒì¼ëª…")

    if '(' in file_name and ')' in file_name:
        suspicious_indicators.append("âš ï¸ ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ (ì´ì „ì— ë‹¤ìš´ë¡œë“œí•œ ì  ìˆìŒ)")

    # ê²½ë¡œ ë¶„ì„
    if 'Downloads' in file_path_str or 'downloads' in file_path_str:
        location_context = "ë‹¤ìš´ë¡œë“œ í´ë”ì—ì„œ ë°œê²¬ - ì¸í„°ë„·ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ"
    elif 'Temp' in file_path_str or 'temp' in file_path_str:
        location_context = "ì„ì‹œ í´ë”ì—ì„œ ë°œê²¬ - ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì´ ìƒì„±í–ˆì„ ê°€ëŠ¥ì„±"
    elif 'Desktop' in file_path_str or 'desktop' in file_path_str:
        location_context = "ë°”íƒ•í™”ë©´ì—ì„œ ë°œê²¬ - ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ë°°ì¹˜"
    else:
        location_context = f"íŠ¹ì • ê²½ë¡œì—ì„œ ë°œê²¬: {file_path_str}"

    # 3. ìœ„í˜‘ í‰ê°€
    prob_ransom = model_result.get('prob_ransom', 0)
    anomalies = model_result.get('anomalies', [])
    features = model_result.get('features', {})

    if prob_ransom >= 0.8:
        threat_level = "ğŸ”´ **ë†’ìŒ** - ì¦‰ê°ì ì¸ ì¡°ì¹˜ í•„ìš”"
    elif prob_ransom >= 0.5:
        threat_level = "ğŸŸ¡ **ì¤‘ê°„** - ì •ë°€ ë¶„ì„ ê¶Œì¥"
    else:
        threat_level = "ğŸŸ¢ **ë‚®ìŒ** - ì¼ìƒì ì¸ ëª¨ë‹ˆí„°ë§"

    # 4. ìŠ¤í† ë¦¬ ìƒì„±
    story = f"""
## ğŸ“– íƒì§€ ìŠ¤í† ë¦¬

**ì–¸ì œ**: {timestamp.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')} ({day_of_week_kr})
- {time_context} {time_risk}

**ì–´ë””ì„œ**: {location_context}

**ë¬´ì—‡ì„**: `{file_name}` íŒŒì¼ ë°œê²¬
- íŒŒì¼ í¬ê¸°: {features.get('file_size_bytes', 0) / 1024 / 1024:.2f} MB
- ì—”íŠ¸ë¡œí”¼: {features.get('entropy', 0):.2f} (ì•”í˜¸í™”/ì••ì¶• ì •ë„)
- PE ì„¹ì…˜ ìˆ˜: {features.get('num_sections', 0)}ê°œ

**ì˜ì‹¬ ì§•í›„**:
"""

    if suspicious_indicators:
        for indicator in suspicious_indicators:
            story += f"- {indicator}\n"
    else:
        story += "- âœ… íŒŒì¼ëª… ë° ê²½ë¡œ íŠ¹ì´ì‚¬í•­ ì—†ìŒ\n"

    story += f"\n**ì´ìƒ íŠ¹ì„± ë¶„ì„**:\n"
    if anomalies:
        for anom in anomalies[:3]:
            story += f"- ğŸ” {anom['description']}: {anom['value']:.2f} (ì •ìƒ í‰ê· : {anom['mean']:.2f}, Z-Score: {anom['z_score']:.2f})\n"
    else:
        story += "- âœ… ëª¨ë“  íŠ¹ì„±ì´ ì •ìƒ ë²”ìœ„ ë‚´\n"

    story += f"""
**ìœ„í˜‘ í‰ê°€**: {threat_level}
- ëœì„¬ì›¨ì–´ ê°€ëŠ¥ì„±: {prob_ransom:.1%}

**ê¶Œì¥ ì¡°ì¹˜**:
"""

    if prob_ransom >= 0.8:
        story += """1. ğŸš¨ **ì¦‰ì‹œ**: í•´ë‹¹ íŒŒì¼ ê²©ë¦¬ ë° ì‚­ì œ
2. ğŸ” **10ë¶„ ì´ë‚´**: ë™ì¼ ì‚¬ìš©ìì˜ ìµœê·¼ í™œë™ ê²€í† 
3. ğŸ›¡ï¸ **1ì‹œê°„ ì´ë‚´**: ì „ì²´ ì‹œìŠ¤í…œ ìŠ¤ìº” ì‹¤ì‹œ
4. ğŸ“Š **ë‹¹ì¼**: ì‚¬ê³  ë³´ê³ ì„œ ì‘ì„± ë° ìƒê¸‰ì ë³´ê³ 
"""
    elif prob_ransom >= 0.5:
        story += """1. ğŸ” ì •ë°€ ë¶„ì„ì„ ìœ„í•´ ì¶”ê°€ ê²€í†  í•„ìš”
2. ğŸ“ í•´ë‹¹ íŒŒì¼ì˜ ì¶œì²˜ í™•ì¸ (ë‹¤ìš´ë¡œë“œ URL, ì´ë©”ì¼ ë“±)
3. ğŸ‘€ 24ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°•í™”
"""
    else:
        story += """1. ğŸ“‹ ì •ìƒ íŒŒì¼ë¡œ íŒë‹¨ë˜ë‚˜ ë¡œê·¸ ê¸°ë¡ ìœ ì§€
2. ğŸ”„ ì •ê¸° ëª¨ë‹ˆí„°ë§ ì§€ì†
"""

    return story

def generate_what_if_scenario(model_result: dict, file_name: str) -> str:
    """'ë§Œì•½ ì´ íŒŒì¼ì´ ì‹¤í–‰ë˜ì—ˆë‹¤ë©´?' ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""

    prob_ransom = model_result.get('prob_ransom', 0)

    # ë‚®ì€ ìœ„í—˜ë„ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì•ˆ í•¨
    if prob_ransom < 0.5:
        return ""

    # ìœ„í—˜ë„ì— ë”°ë¥¸ ì‹œë‚˜ë¦¬ì˜¤
    if prob_ransom >= 0.8:
        # ê³ ìœ„í—˜: ì „í˜•ì ì¸ ëœì„¬ì›¨ì–´ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤
        scenario = f"""
## ğŸ¬ What-If ì‹œë‚˜ë¦¬ì˜¤: ë§Œì•½ `{file_name}`ì´ ì‹¤í–‰ë˜ì—ˆë‹¤ë©´?

> âš ï¸ **ê²½ê³ **: ì´ê²ƒì€ ì‹¤ì œ ì‹¤í–‰ë˜ì§€ ì•Šì€ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤.

### ğŸ“… ì˜ˆìƒ ê³µê²© íƒ€ì„ë¼ì¸

**T+0ì´ˆ** - íŒŒì¼ ì‹¤í–‰
- ğŸ‘¤ ì‚¬ìš©ìê°€ `{file_name}` ë”ë¸”í´ë¦­
- ğŸ’» Windowsì—ì„œ ì‹¤í–‰ í™•ì¸ ëŒ€í™”ìƒì í‘œì‹œ
- âœ… ì‚¬ìš©ìê°€ "ì˜ˆ" í´ë¦­

**T+2ì´ˆ** - ğŸ”´ ì´ˆê¸° ì¹¨íˆ¬
- ğŸ›¡ï¸ Windows Defender ìš°íšŒ ì‹œë„
- ğŸ”“ ê´€ë¦¬ì ê¶Œí•œ ìƒìŠ¹ ì‹œë„ (UAC bypass)
- ğŸ“‚ ì‹œìŠ¤í…œ í´ë”ì— ìì‹ ì„ ë³µì‚¬ (`C:\\Windows\\System32\\`)

**T+5ì´ˆ** - ğŸ”´ ì„€ë„ìš° ì¹´í”¼ ì‚­ì œ
- ğŸ’€ `vssadmin.exe delete shadows /all /quiet` ì‹¤í–‰
- ğŸ—‘ï¸ ëª¨ë“  ë°±ì—… ë³µì› ì§€ì  ì‚­ì œ
- âŒ **ë³µêµ¬ ë¶ˆê°€ëŠ¥ ìƒíƒœë¡œ ë§Œë“¦**

**T+10ì´ˆ** - ğŸ”´ ë‚´ë¶€ë§ ìŠ¤ìº” ì‹œì‘
- ğŸŒ ë‚´ë¶€ IP ëŒ€ì—­ ìŠ¤ìº” (192.168.x.x)
- ğŸ” SMB í¬íŠ¸(445) ì—´ë¦° PC ì°¾ê¸°
- ğŸ“¡ ê³µìœ  í´ë” íƒìƒ‰

**T+30ì´ˆ** - ğŸ”´ íŒŒì¼ ì•”í˜¸í™” ì‹œì‘
- ğŸ“ ìš°ì„ ìˆœìœ„ 1: ë¬¸ì„œ íŒŒì¼ (`.docx`, `.xlsx`, `.pdf`)
- ğŸ“¸ ìš°ì„ ìˆœìœ„ 2: ì´ë¯¸ì§€ íŒŒì¼ (`.jpg`, `.png`)
- ğŸ’¾ ìš°ì„ ìˆœìœ„ 3: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ (`.db`, `.sql`)
- ğŸ” AES-256 ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

**T+5ë¶„** - ğŸ”´ ëŒ€ê·œëª¨ ì•”í˜¸í™” ì§„í–‰ ì¤‘
- ğŸ“Š ì•½ 1,000ê°œ íŒŒì¼ ì•”í˜¸í™” ì™„ë£Œ
- ğŸš€ ì•”í˜¸í™” ì†ë„: ì•½ 200ê°œ íŒŒì¼/ë¶„
- ğŸ“ˆ CPU ì‚¬ìš©ë¥  90% ì´ìƒ

**T+10ë¶„** - ğŸ”´ ëœì„¬ ë…¸íŠ¸ í‘œì‹œ
```
ğŸ˜ˆ YOUR FILES HAVE BEEN ENCRYPTED! ğŸ˜ˆ

All your important files (documents, photos, databases)
have been encrypted with military-grade encryption.

ğŸ” The ONLY way to decrypt your files is to pay:
   - Amount: 0.5 BTC (~â‚©30,000,000)
   - Bitcoin Address: 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa
   - Deadline: 72 hours

â° After 72 hours, the decryption key will be DELETED FOREVER!
ğŸ“§ Contact: darknet@ransomhelp.onion
```

**T+30ë¶„** - ğŸ”´ ë‚´ë¶€ë§ í™•ì‚° ì‹œë„
- ğŸŒŠ SMB EternalBlue ì·¨ì•½ì  ì•…ìš©
- ğŸ’» 3ëŒ€ì˜ ì¶”ê°€ PC ê°ì—¼
- ğŸ—‚ï¸ ë„¤íŠ¸ì›Œí¬ ê³µìœ  ë“œë¼ì´ë¸Œ ì•”í˜¸í™”

**T+1ì‹œê°„** - ğŸ”´ ë°ì´í„° íƒˆì·¨ ì‹œë„
- ğŸ“¤ ë¯¼ê°í•œ íŒŒì¼ C&C ì„œë²„ë¡œ ì „ì†¡
- ğŸ’³ ë¸Œë¼ìš°ì €ì— ì €ì¥ëœ ë¹„ë°€ë²ˆí˜¸ ìˆ˜ì§‘
- ğŸ“§ ì´ë©”ì¼ ê³„ì • ì •ë³´ íƒˆì·¨

---

### ğŸ’¥ ì˜ˆìƒ í”¼í•´ ê·œëª¨

**íŒŒì¼ í”¼í•´**:
- ğŸ”´ ì•”í˜¸í™”ëœ íŒŒì¼: **ì•½ 5,000ê°œ** (ë‚´ë¶€ë§ í¬í•¨)
- ğŸ“ ì†ì‹¤ëœ ë°ì´í„°: **ì•½ 50GB**
- âŒ ë³µêµ¬ ê°€ëŠ¥ì„±: **0%** (ì„€ë„ìš° ì¹´í”¼ ì‚­ì œë¨)

**ì‹œìŠ¤í…œ í”¼í•´**:
- ğŸ’» ê°ì—¼ëœ PC: **4ëŒ€**
- ğŸ—‚ï¸ ì†ìƒëœ ë„¤íŠ¸ì›Œí¬ ë“œë¼ì´ë¸Œ: **2ê°œ**
- â±ï¸ ì˜ˆìƒ ë‹¤ìš´íƒ€ì„: **ìµœì†Œ 3ì¼**

**ì¬ë¬´ í”¼í•´** (í•œêµ­ ì›í™”):
- ğŸ’° ëª¸ê°’ ìš”êµ¬ì•¡: **â‚©30,000,000** (0.5 BTC)
- ğŸ’¸ ë³µêµ¬ ë¹„ìš©: **â‚©5,000,000** (ì „ë¬¸ ì—…ì²´)
- ğŸ“‰ ìƒì‚°ì„± ì†ì‹¤: **â‚©15,000,000** (3ì¼ Ã— â‚©5,000,000/ì¼)
- ğŸ“Š **ì´ ì˜ˆìƒ ì†ì‹¤: â‚©50,000,000**

**ë²•ì /í‰íŒ ë¦¬ìŠ¤í¬**:
- âš–ï¸ ê°œì¸ì •ë³´ë³´í˜¸ë²• ìœ„ë°˜ ê°€ëŠ¥ì„±
- ğŸ“¢ ì–¸ë¡  ë³´ë„ ë° í‰íŒ ì†ìƒ
- ğŸ‘¥ ê³ ê° ì‹ ë¢° í•˜ë½

---

### âœ… ë‹¤í–‰íˆ ë§‰ì€ ê²°ê³¼

**ì‹¤ì œ ê²°ê³¼**:
- âœ… íŒŒì¼ ì‹¤í–‰ ì „ íƒì§€ ì„±ê³µ
- âœ… í”¼í•´ì•¡: **â‚©0**
- âœ… ì˜ˆë°©í•œ ì†ì‹¤: **â‚©50,000,000**

**ë³´ì•ˆ ì‹œìŠ¤í…œ ROI**:
- ğŸ’¡ ì´ë²ˆ í•œ ë²ˆì˜ íƒì§€ë¡œ **â‚©50,000,000 ì ˆì•½**
- ğŸ¯ ë³´ì•ˆ íˆ¬ì íš¨ê³¼ ì…ì¦
"""
    else:
        # ì¤‘ìœ„í—˜: ë¶€ë¶„ì  í”¼í•´ ì‹œë‚˜ë¦¬ì˜¤
        scenario = f"""
## ğŸ¬ What-If ì‹œë‚˜ë¦¬ì˜¤: ë§Œì•½ `{file_name}`ì´ ì‹¤í–‰ë˜ì—ˆë‹¤ë©´?

> âš ï¸ **ê²½ê³ **: ì´ê²ƒì€ ì‹¤ì œ ì‹¤í–‰ë˜ì§€ ì•Šì€ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤.

### ğŸ“… ì˜ˆìƒ ê³µê²© íƒ€ì„ë¼ì¸

**T+0ì´ˆ** - íŒŒì¼ ì‹¤í–‰
- ğŸ‘¤ ì‚¬ìš©ìê°€ `{file_name}` ë”ë¸”í´ë¦­

**T+5ì´ˆ** - ğŸŸ¡ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë™ì‘
- ğŸ” ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
- ğŸ“‚ ì¼ë¶€ íŒŒì¼ ì•”í˜¸í™” ì‹œë„

**T+30ì´ˆ** - ğŸŸ¡ ì œí•œì  í”¼í•´
- ğŸ“ ì•½ 100-500ê°œ íŒŒì¼ ì•”í˜¸í™”
- ğŸ” ì¤‘ìš” ì‹œìŠ¤í…œ íŒŒì¼ì€ ì•ˆì „

**T+5ë¶„** - ğŸŸ¡ ëœì„¬ ë…¸íŠ¸ í‘œì‹œ
- ğŸ’° ëª¸ê°’: â‚©5,000,000 ~ â‚©10,000,000

---

### ğŸ’¥ ì˜ˆìƒ í”¼í•´ ê·œëª¨

**íŒŒì¼ í”¼í•´**:
- ğŸŸ¡ ì•”í˜¸í™”ëœ íŒŒì¼: **ì•½ 500ê°œ**
- ğŸ“ ì†ì‹¤ëœ ë°ì´í„°: **ì•½ 5GB**

**ì¬ë¬´ í”¼í•´**:
- ğŸ’° ëª¸ê°’: **â‚©5,000,000**
- ğŸ’¸ ë³µêµ¬ ë¹„ìš©: **â‚©1,000,000**
- ğŸ“‰ ìƒì‚°ì„± ì†ì‹¤: **â‚©3,000,000**
- ğŸ“Š **ì´ ì˜ˆìƒ ì†ì‹¤: â‚©9,000,000**

---

### âœ… ë‹¤í–‰íˆ ë§‰ì€ ê²°ê³¼

- âœ… íŒŒì¼ ì‹¤í–‰ ì „ íƒì§€ ì„±ê³µ
- âœ… ì˜ˆë°©í•œ ì†ì‹¤: **â‚©9,000,000**
"""

    return scenario

def calculate_business_impact(model_result: dict, file_name: str) -> dict:
    """
    ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ í•œêµ­ ì›í™”(â‚©)ë¡œ ê³„ì‚°

    Args:
        model_result: ëª¨ë¸ ë¶„ì„ ê²°ê³¼
        file_name: íŒŒì¼ëª…

    Returns:
        dict: ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ìƒì„¸ ì •ë³´
    """

    prob_ransom = model_result.get('prob_ransom', 0)

    # ìœ„í—˜ë„ì— ë”°ë¥¸ ê¸°ë³¸ ì†ì‹¤ ê·œëª¨ ì„¤ì •
    if prob_ransom >= 0.8:
        # ê³ ìœ„í—˜: ëŒ€ê·œëª¨ í”¼í•´ ì‹œë‚˜ë¦¬ì˜¤
        base_damage = {
            'ransom_demand': 50000000,        # ëª¸ê°’: â‚©50,000,000
            'recovery_cost': 15000000,        # ë³µêµ¬ ë¹„ìš©: â‚©15,000,000
            'downtime_cost_per_hour': 8000000, # ì‹œê°„ë‹¹ ìƒì‚°ì„± ì†ì‹¤: â‚©8,000,000
            'downtime_hours': 72,             # ì˜ˆìƒ ì¤‘ë‹¨ ì‹œê°„: 72ì‹œê°„ (3ì¼)
            'data_loss_cost': 30000000,       # ë°ì´í„° ì†ì‹¤ ë¹„ìš©: â‚©30,000,000
            'legal_compliance_cost': 20000000, # ë²•ì /ê·œì œ ëŒ€ì‘ ë¹„ìš©: â‚©20,000,000
            'reputation_damage': 100000000,   # í‰íŒ ì†ì‹¤: â‚©100,000,000
            'customer_compensation': 25000000, # ê³ ê° ë³´ìƒ: â‚©25,000,000
            'security_upgrade_cost': 50000000, # ë³´ì•ˆ ê°•í™” ë¹„ìš©: â‚©50,000,000
        }
    elif prob_ransom >= 0.5:
        # ì¤‘ìœ„í—˜: ì¤‘ê°„ ê·œëª¨ í”¼í•´ ì‹œë‚˜ë¦¬ì˜¤
        base_damage = {
            'ransom_demand': 5000000,         # ëª¸ê°’: â‚©5,000,000
            'recovery_cost': 1000000,         # ë³µêµ¬ ë¹„ìš©: â‚©1,000,000
            'downtime_cost_per_hour': 500000, # ì‹œê°„ë‹¹ ìƒì‚°ì„± ì†ì‹¤: â‚©500,000
            'downtime_hours': 24,             # ì˜ˆìƒ ì¤‘ë‹¨ ì‹œê°„: 24ì‹œê°„ (1ì¼)
            'data_loss_cost': 3000000,        # ë°ì´í„° ì†ì‹¤ ë¹„ìš©: â‚©3,000,000
            'legal_compliance_cost': 2000000, # ë²•ì /ê·œì œ ëŒ€ì‘ ë¹„ìš©: â‚©2,000,000
            'reputation_damage': 5000000,     # í‰íŒ ì†ì‹¤: â‚©5,000,000
            'customer_compensation': 1000000, # ê³ ê° ë³´ìƒ: â‚©1,000,000
            'security_upgrade_cost': 3000000, # ë³´ì•ˆ ê°•í™” ë¹„ìš©: â‚©3,000,000
        }
    else:
        # ì €ìœ„í—˜: ì†Œê·œëª¨ í”¼í•´ ì‹œë‚˜ë¦¬ì˜¤
        base_damage = {
            'ransom_demand': 1000000,         # ëª¸ê°’: â‚©1,000,000
            'recovery_cost': 300000,          # ë³µêµ¬ ë¹„ìš©: â‚©300,000
            'downtime_cost_per_hour': 200000, # ì‹œê°„ë‹¹ ìƒì‚°ì„± ì†ì‹¤: â‚©200,000
            'downtime_hours': 8,              # ì˜ˆìƒ ì¤‘ë‹¨ ì‹œê°„: 8ì‹œê°„
            'data_loss_cost': 500000,         # ë°ì´í„° ì†ì‹¤ ë¹„ìš©: â‚©500,000
            'legal_compliance_cost': 500000,  # ë²•ì /ê·œì œ ëŒ€ì‘ ë¹„ìš©: â‚©500,000
            'reputation_damage': 1000000,     # í‰íŒ ì†ì‹¤: â‚©1,000,000
            'customer_compensation': 300000,  # ê³ ê° ë³´ìƒ: â‚©300,000
            'security_upgrade_cost': 1000000, # ë³´ì•ˆ ê°•í™” ë¹„ìš©: â‚©1,000,000
        }

    # ì´ ë‹¤ìš´íƒ€ì„ ë¹„ìš© ê³„ì‚°
    total_downtime_cost = base_damage['downtime_cost_per_hour'] * base_damage['downtime_hours']

    # ì´ ì§ì ‘ í”¼í•´ì•¡
    direct_damage = (
        base_damage['ransom_demand'] +
        base_damage['recovery_cost'] +
        total_downtime_cost +
        base_damage['data_loss_cost']
    )

    # ì´ ê°„ì ‘ í”¼í•´ì•¡
    indirect_damage = (
        base_damage['legal_compliance_cost'] +
        base_damage['reputation_damage'] +
        base_damage['customer_compensation'] +
        base_damage['security_upgrade_cost']
    )

    # ì´ ì˜ˆìƒ ì†ì‹¤
    total_estimated_loss = direct_damage + indirect_damage

    # ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ í‰ê°€
    legal_risk = {
        'level': 'ë†’ìŒ' if prob_ransom >= 0.8 else 'ì¤‘ê°„' if prob_ransom >= 0.5 else 'ë‚®ìŒ',
        'personal_info_breach': prob_ransom >= 0.7,  # ê°œì¸ì •ë³´ ìœ ì¶œ ê°€ëŠ¥ì„±
        'reporting_required': prob_ransom >= 0.7,     # ì‹ ê³  ì˜ë¬´ ë°œìƒ ê°€ëŠ¥ì„±
        'regulatory_violations': []
    }

    if prob_ransom >= 0.7:
        legal_risk['regulatory_violations'].extend([
            'ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ34ì¡°(ê°œì¸ì •ë³´ ìœ ì¶œ í†µì§€)',
            'ì •ë³´í†µì‹ ë§ë²• ì œ27ì¡°ì˜3(ì •ë³´ë³´í˜¸ ìµœê³ ì±…ì„ì ì§€ì •)'
        ])

    if prob_ransom >= 0.8:
        legal_risk['regulatory_violations'].extend([
            'ì „ìê¸ˆìœµê±°ë˜ë²• ì œ21ì¡°(ì „ìê¸ˆìœµì‚¬ê³  ì¡°ì‚¬ ë° ë³´ê³ )',
            'ISMS ì¸ì¦ ìœ ì§€ ì˜ë¬´ ìœ„ë°˜ ê°€ëŠ¥ì„±'
        ])

    # ROI ê³„ì‚° (ë³´ì•ˆ ì‹œìŠ¤í…œì´ ì´ ìœ„í˜‘ì„ ë§‰ì•˜ì„ ë•Œì˜ ê°€ì¹˜)
    # í‰ê·  ë³´ì•ˆ ì‹œìŠ¤í…œ ì—°ê°„ ìš´ì˜ ë¹„ìš©: â‚©30,000,000 ê°€ì •
    security_system_annual_cost = 30000000

    # ì´ë²ˆ íƒì§€ë¡œ ì¸í•œ ROI ê¸°ì—¬ë„
    roi_contribution = total_estimated_loss / security_system_annual_cost if security_system_annual_cost > 0 else 0

    return {
        'risk_level': 'ê³ ìœ„í—˜' if prob_ransom >= 0.8 else 'ì¤‘ìœ„í—˜' if prob_ransom >= 0.5 else 'ì €ìœ„í—˜',
        'probability': prob_ransom,

        # ì§ì ‘ í”¼í•´
        'direct_damage': {
            'ransom_demand': base_damage['ransom_demand'],
            'recovery_cost': base_damage['recovery_cost'],
            'downtime_cost': total_downtime_cost,
            'downtime_hours': base_damage['downtime_hours'],
            'data_loss_cost': base_damage['data_loss_cost'],
            'total': direct_damage
        },

        # ê°„ì ‘ í”¼í•´
        'indirect_damage': {
            'legal_compliance_cost': base_damage['legal_compliance_cost'],
            'reputation_damage': base_damage['reputation_damage'],
            'customer_compensation': base_damage['customer_compensation'],
            'security_upgrade_cost': base_damage['security_upgrade_cost'],
            'total': indirect_damage
        },

        # ì´ ì†ì‹¤
        'total_estimated_loss': total_estimated_loss,

        # ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬
        'legal_risk': legal_risk,

        # ROI
        'roi': {
            'prevented_loss': total_estimated_loss,
            'security_system_annual_cost': security_system_annual_cost,
            'roi_multiple': round(roi_contribution, 2),
            'roi_percentage': round(roi_contribution * 100, 1)
        }
    }

def handle_action(file_path: Path, model_result: dict, **kwargs):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•˜ê³  ìë™ìœ¼ë¡œ ì¼ê°„ ë³´ê³ ì„œ ìƒì„±"""

    timestamp = datetime.now()

    # íƒì§€ ìŠ¤í† ë¦¬ ìƒì„±
    detection_story = generate_detection_story(file_path, model_result, timestamp)

    # What-If ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    what_if_scenario = generate_what_if_scenario(model_result, file_path.name)

    # ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ê³„ì‚°
    business_impact = calculate_business_impact(model_result, file_path.name)

    log_entry = {
        "timestamp": timestamp.isoformat(),
        "file_name": file_path.name,
        "file_path": str(file_path),
        "label": model_result.get("label"),
        "probability": model_result.get("prob_ransom"),
        "anomalies": model_result.get("anomalies", []),
        "features": model_result.get("features", {}),
        "detection_story": detection_story,
        "what_if_scenario": what_if_scenario,
        "business_impact": business_impact,
        "action": "log",
        "action_result": "success"
    }

    log_file = LOGS_DIR / "events.jsonl"
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

    # ìë™ìœ¼ë¡œ ì¼ê°„ ë³´ê³ ì„œ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œ, UIì— í‘œì‹œ ì•ˆ í•¨)
    try:
        today = datetime.now().date()
        generate_daily_report(target_date=today, use_ai=True)
    except Exception as e:
        # ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨í•´ë„ ë¡œê·¸ ê¸°ë¡ì€ ì„±ê³µ ì²˜ë¦¬
        pass

    return log_entry

@st.cache_resource
def start_watcher_service():
    """Watchdog ì˜µì €ë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘í•˜ê³  íë¥¼ ë°˜í™˜"""
    file_queue = queue.Queue()
    event_handler = WatcherEventHandler(file_queue)
    observer = Observer()
    observer.schedule(event_handler, str(DOWNLOAD_DIR), recursive=False)

    thread = threading.Thread(target=observer.start, daemon=True)
    thread.start()

    return observer, file_queue

# --- 9. í˜ì´ì§€ 1: ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ---
def render_realtime_soc_dashboard():
    """í˜ì´ì§€ 1: ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ ëŒ€ì‹œë³´ë“œ (ê°•í™” ë²„ì „)"""
    st.header("ğŸ“¡ ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ")
    st.markdown("---")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'monitoring_started' not in st.session_state:
        st.session_state.monitoring_started = False
    if 'last_analysis_result' not in st.session_state:
        st.session_state.last_analysis_result = None

    # "ê´€ì œ ì‹œì‘" ë²„íŠ¼
    if not st.session_state.monitoring_started:
        if st.button("â–¶ï¸ ê´€ì œ ì‹œì‘", type="primary", use_container_width=True):
            st.session_state.monitoring_started = True
            st.rerun()
        st.info(f"'{DOWNLOAD_DIR}' í´ë”ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì‹œí•˜ë ¤ë©´ 'ê´€ì œ ì‹œì‘' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
        return

    # --- ê´€ì œ ì‹œì‘ í›„ UI ---
    observer, file_queue = start_watcher_service()

    # ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹œ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆë§Œ í‘œì‹œ
    if 'monitoring_toast_shown' not in st.session_state:
        st.toast(f"ë‹¤ìš´ë¡œë“œ í´ë” ê°ì‹œ ì‹œì‘: {DOWNLOAD_DIR}", icon="ğŸ‘€")
        st.session_state.monitoring_toast_shown = True

    st.success(f"âœ… **ê°ì‹œ ì¤‘:** '{DOWNLOAD_DIR}' í´ë”")

    # --- ê¸°ê°„ ì„ íƒ íƒ­ ---
    st.markdown("---")
    st.subheader("ğŸ“Š ë³´ì•ˆ ê´€ì œ ëŒ€ì‹œë³´ë“œ")

    period_tab1, period_tab2, period_tab3, period_tab4 = st.tabs(["ğŸ”´ ì‹¤ì‹œê°„", "ğŸ“… ì¼ê°„", "ğŸ“† ì£¼ê°„", "ğŸ“ˆ ì›”ê°„"])

    # ë¡œê·¸ ë°ì´í„° ë¡œë“œ
    df_all = load_events_log()

    # --- íƒ­ 1: ì‹¤ì‹œê°„ ---
    # --- íƒ­ 1: ì‹¤ì‹œê°„ ---
    with period_tab1:
        render_period_dashboard(df_all, "ì‹¤ì‹œê°„")
        
        # ì‹¤ì‹œê°„ íƒ­ì—ë§Œ ìˆëŠ” ì¶”ê°€ ê¸°ëŠ¥ë“¤
        st.markdown("---")
        
        # íŒŒì¼ í ì²˜ë¦¬
        files_processed = False
        try:
            while True:
                file_path = file_queue.get_nowait()
                files_processed = True
                
                if file_path.suffix.lower() not in ANALYSIS_EXTENSIONS:
                    st.toast(f"ë¶„ì„ ëŒ€ìƒ ì•„ë‹˜ (ë¬´ì‹œ): {file_path.name}", icon="ğŸ¤·")
                    continue
                
                st.toast(f"'{file_path.name}' íŒŒì¼ ë¶„ì„ ì¤‘...", icon="â±ï¸")
                
                if not _wait_until_download_complete(file_path):
                    st.warning(f"'{file_path.name}' íŒŒì¼ì´ ì•ˆì •í™”ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                try:
                    features = extract_pe_header_features(file_path)
                    result = ransomware_model.predict_with_explanation(features)
                    
                    analysis_payload = {"file_name": file_path.name, "result": result}
                    st.session_state.last_analysis_result = analysis_payload
                    
                    handle_action(file_path=file_path, model_result=result)
                    
                    st.toast("ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ë¸Œë¦¬í•‘ ìš”ì²­ ì¤‘...", icon="ğŸ§ ")
                    summary = get_ai_summary(analysis_payload)
                    st.session_state.ai_summary = summary
                    st.session_state.show_analysis_complete_toast = file_path.name
                    
                except Exception as e:
                    st.error(f"âŒ '{file_path.name}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
                    st.code(traceback.format_exc())
        
        except queue.Empty:
            pass
        
        # í† ìŠ¤íŠ¸ ì•Œë¦¼ í‘œì‹œ
        if st.session_state.get("show_analysis_complete_toast"):
            file_name = st.session_state.show_analysis_complete_toast
            st.toast(f"âœ… '{file_name}' íŒŒì¼ ë¶„ì„ ì™„ë£Œ!", icon="âœ…")
            st.session_state.show_analysis_complete_toast = None

        if files_processed:
            st.rerun()

        # íŒŒì¼ì´ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ì–´ë„ ì£¼ê¸°ì ìœ¼ë¡œ í í™•ì¸ì„ ìœ„í•´ ì§§ì€ ì§€ì—° í›„ rerun
        # ë‹¨, ë„ˆë¬´ ë¹ ë¥´ê²Œ ê¹œë¹¡ì´ì§€ ì•Šë„ë¡ 3ì´ˆ ê°„ê²© ìœ ì§€
        time.sleep(3)
        st.rerun()

        # ìµœì‹  ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if st.session_state.last_analysis_result:
            analysis = st.session_state.last_analysis_result
            result = analysis['result']
            label = result['label']
            prob = result['prob_ransom']
            anomalies = result['anomalies']

            st.subheader(f"ğŸ“œ ìµœì‹  ë¶„ì„ ê²°ê³¼: '{analysis['file_name']}'")

            # íƒì§€ ìŠ¤í† ë¦¬ & What-If ì‹œë‚˜ë¦¬ì˜¤ í‘œì‹œ (ê°€ì¥ ìµœê·¼ ë¡œê·¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
            df_latest = load_events_log()
            if not df_latest.empty:
                latest_log = df_latest.iloc[0]

                # íƒì§€ ìŠ¤í† ë¦¬
                if 'detection_story' in df_latest.columns:
                    latest_story = latest_log.get('detection_story', '')
                    if latest_story:
                        with st.expander("ğŸ“– íƒì§€ ìŠ¤í† ë¦¬ ë³´ê¸°", expanded=True):
                            st.markdown(latest_story)

                # What-If ì‹œë‚˜ë¦¬ì˜¤
                if 'what_if_scenario' in df_latest.columns:
                    what_if = latest_log.get('what_if_scenario', '')
                    if what_if:
                        with st.expander("ğŸ¬ What-If ì‹œë‚˜ë¦¬ì˜¤ ë³´ê¸° (ë§Œì•½ ì‹¤í–‰ë˜ì—ˆë‹¤ë©´?)", expanded=(prob >= 0.8)):
                            st.markdown(what_if)

                # ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸
                if 'business_impact' in df_latest.columns:
                    impact = latest_log.get('business_impact', {})
                    if impact:
                        with st.expander("ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„ (Business Impact)", expanded=(prob >= 0.5)):
                            st.markdown(f"### ğŸ“Š ìœ„í—˜ë„: **{impact.get('risk_level', 'N/A')}** (í™•ë¥ : {impact.get('probability', 0):.1%})")

                            # ì´ ì˜ˆìƒ ì†ì‹¤
                            total_loss = impact.get('total_estimated_loss', 0)
                            st.markdown(f"### ğŸ’¸ ì´ ì˜ˆìƒ ì†ì‹¤: **â‚©{total_loss:,}**")

                            st.markdown("---")

                            # ì§ì ‘ í”¼í•´
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("#### ğŸ“ ì§ì ‘ í”¼í•´")
                                direct = impact.get('direct_damage', {})
                                st.markdown(f"""
- **ëª¸ê°’ ìš”êµ¬ì•¡:** â‚©{direct.get('ransom_demand', 0):,}
- **ë³µêµ¬ ë¹„ìš©:** â‚©{direct.get('recovery_cost', 0):,}
- **ë‹¤ìš´íƒ€ì„ ì†ì‹¤:** â‚©{direct.get('downtime_cost', 0):,} ({direct.get('downtime_hours', 0)}ì‹œê°„)
- **ë°ì´í„° ì†ì‹¤:** â‚©{direct.get('data_loss_cost', 0):,}
- **ì†Œê³„:** â‚©{direct.get('total', 0):,}
""")

                            # ê°„ì ‘ í”¼í•´
                            with col2:
                                st.markdown("#### ğŸ“ ê°„ì ‘ í”¼í•´")
                                indirect = impact.get('indirect_damage', {})
                                st.markdown(f"""
- **ë²•ì /ê·œì œ ëŒ€ì‘:** â‚©{indirect.get('legal_compliance_cost', 0):,}
- **í‰íŒ ì†ì‹¤:** â‚©{indirect.get('reputation_damage', 0):,}
- **ê³ ê° ë³´ìƒ:** â‚©{indirect.get('customer_compensation', 0):,}
- **ë³´ì•ˆ ê°•í™” ë¹„ìš©:** â‚©{indirect.get('security_upgrade_cost', 0):,}
- **ì†Œê³„:** â‚©{indirect.get('total', 0):,}
""")

                            st.markdown("---")

                            # ë²•ì  ë¦¬ìŠ¤í¬
                            legal = impact.get('legal_risk', {})
                            st.markdown(f"#### âš–ï¸ ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬: **{legal.get('level', 'N/A')}**")

                            if legal.get('personal_info_breach'):
                                st.warning("âš ï¸ ê°œì¸ì •ë³´ ìœ ì¶œ ê°€ëŠ¥ì„± ìˆìŒ")

                            if legal.get('reporting_required'):
                                st.error("ğŸš¨ ë²•ì  ì‹ ê³  ì˜ë¬´ ë°œìƒ ê°€ëŠ¥")

                            violations = legal.get('regulatory_violations', [])
                            if violations:
                                st.markdown("**ìœ„ë°˜ ê°€ëŠ¥ ë²•ê·œ:**")
                                for v in violations:
                                    st.markdown(f"- {v}")

                            st.markdown("---")

                            # ROI
                            roi = impact.get('roi', {})
                            st.markdown("#### ğŸ“ˆ ë³´ì•ˆ ì‹œìŠ¤í…œ ROI ê¸°ì—¬")
                            st.markdown(f"""
- **ì˜ˆë°©í•œ ì†ì‹¤:** â‚©{roi.get('prevented_loss', 0):,}
- **ë³´ì•ˆ ì‹œìŠ¤í…œ ì—°ê°„ ë¹„ìš©:** â‚©{roi.get('security_system_annual_cost', 0):,}
- **ROI ë°°ìˆ˜:** **{roi.get('roi_multiple', 0)}ë°°**
- **ROI í¼ì„¼íŠ¸:** **{roi.get('roi_percentage', 0)}%**
""")

                            if roi.get('roi_multiple', 0) >= 1:
                                st.success(f"âœ… ì´ë²ˆ íƒì§€ë§Œìœ¼ë¡œ ë³´ì•ˆ ì‹œìŠ¤í…œ ì—°ê°„ ë¹„ìš©ì˜ **{roi.get('roi_multiple', 0)}ë°°** ê°€ì¹˜ ì°½ì¶œ!")

            if st.session_state.get("ai_summary"):
                with st.expander("ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ë¸Œë¦¬í•‘ ë³´ê¸°", expanded=False):
                    st.markdown(st.session_state.ai_summary)

            if label == 1:
                st.error(f"**ğŸš¨ ëœì„¬ì›¨ì–´ ì˜ì‹¬ (í™•ë¥ : {prob:.2%})**")
            else:
                st.success(f"**âœ… ì •ìƒ íŒŒì¼ë¡œ íŒë‹¨ (ëœì„¬ì›¨ì–´ í™•ë¥ : {prob:.2%})**")

            if anomalies:
                st.warning("ì£¼ìš” ì´ìƒ ì§•í›„:")
                for anom in anomalies[:5]:
                    st.markdown(f"- **{anom['description']}** (`{anom['feature']}`: `{anom['value']:.2f}`)")
            st.markdown("---")
    
    # --- íƒ­ 2: ì¼ê°„ ---
    with period_tab2:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown("### ğŸ“… ì¼ê°„ ì´ìƒ íŒŒì¼ íƒì§€ ëŒ€ì‹œë³´ë“œ")
        with col2:
            selected_date = st.date_input("ë‚ ì§œ ì„ íƒ", value=datetime.now().date(), key="daily_date")
        
        df_daily = filter_by_period(df_all, 'daily', selected_date)
        render_period_dashboard(df_daily, f"ì¼ê°„ ({selected_date})")
    
    # --- íƒ­ 3: ì£¼ê°„ ---
    with period_tab3:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown("### ğŸ“† ì£¼ê°„ ì´ìƒ íŒŒì¼ íƒì§€ ëŒ€ì‹œë³´ë“œ")
        with col2:
            today = datetime.now()
            week_num = today.isocalendar()[1]
            selected_week = st.number_input("ì£¼ì°¨ ì„ íƒ", min_value=1, max_value=53, value=week_num, key="weekly_week")
        
        # ì„ íƒëœ ì£¼ì˜ ì‹œì‘ ë‚ ì§œ ê³„ì‚°
        target_date = datetime.strptime(f'{today.year}-W{int(selected_week)}-1', "%Y-W%W-%w")
        df_weekly = filter_by_period(df_all, 'weekly', target_date)
        render_period_dashboard(df_weekly, f"ì£¼ê°„ ({today.year}ë…„ {int(selected_week)}ì£¼ì°¨)")
    
    # --- íƒ­ 4: ì›”ê°„ ---
    with period_tab4:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown("### ğŸ“ˆ ì›”ê°„ ì´ìƒ íŒŒì¼ íƒì§€ ëŒ€ì‹œë³´ë“œ")
        with col2:
            selected_month = st.selectbox(
                "ì›” ì„ íƒ",
                options=list(range(1, 13)),
                index=datetime.now().month - 1,
                format_func=lambda x: f"{x}ì›”",
                key="monthly_month"
            )
        
        target_date = datetime(datetime.now().year, selected_month, 1)
        df_monthly = filter_by_period(df_all, 'monthly', target_date)
        render_period_dashboard(df_monthly, f"ì›”ê°„ ({datetime.now().year}ë…„ {selected_month}ì›”)")


# --- 10. ì‚¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ ---
INCIDENTS_FILE = LOGS_DIR / "incidents.json"

def load_incidents():
    """ì‚¬ê³  ëª©ë¡ ë¡œë“œ"""
    if not INCIDENTS_FILE.exists():
        return []
    try:
        with open(INCIDENTS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return []

def save_incidents(incidents):
    """ì‚¬ê³  ëª©ë¡ ì €ì¥"""
    with open(INCIDENTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(incidents, f, ensure_ascii=False, indent=2)

def create_incident_from_detection(log_entry):
    """íƒì§€ ë¡œê·¸ë¡œë¶€í„° ì‚¬ê³  ìƒì„±"""
    incident = {
        "incident_id": f"INC-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
        "created_at": datetime.now().isoformat(),
        "file_name": log_entry.get("file_name"),
        "file_path": log_entry.get("file_path"),
        "probability": log_entry.get("probability", 0),
        "status": "íƒì§€ë¨",  # íƒì§€ë¨ â†’ ë¶„ì„ì¤‘ â†’ ê²©ë¦¬ë¨ â†’ ë³µêµ¬ì¤‘ â†’ ì™„ë£Œ
        "priority": "ë†’ìŒ" if log_entry.get("probability", 0) > 0.7 else "ì¤‘ê°„",
        "assigned_to": "ë¯¸ì§€ì •",
        "timeline": [
            {
                "timestamp": datetime.now().isoformat(),
                "status": "íƒì§€ë¨",
                "description": f"ëœì„¬ì›¨ì–´ íƒì§€ (í™•ë¥ : {log_entry.get('probability', 0):.2%})"
            }
        ],
        "checklist": [
            {"task": "ì´ˆê¸° ë¶„ì„ ì™„ë£Œ", "completed": False},
            {"task": "ì˜í–¥ ë²”ìœ„ íŒŒì•…", "completed": False},
            {"task": "íŒŒì¼ ê²©ë¦¬/ì‚­ì œ", "completed": False},
            {"task": "ì‹œìŠ¤í…œ ìŠ¤ìº” ì‹¤ì‹œ", "completed": False},
            {"task": "ë°±ì—… ë³µêµ¬ í™•ì¸", "completed": False},
            {"task": "ì‚¬ê³  ë³´ê³ ì„œ ì‘ì„±", "completed": False}
        ],
        "notes": []
    }
    return incident

def update_incident_status(incident_id, new_status, description=""):
    """ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸"""
    incidents = load_incidents()
    for inc in incidents:
        if inc["incident_id"] == incident_id:
            inc["status"] = new_status
            inc["timeline"].append({
                "timestamp": datetime.now().isoformat(),
                "status": new_status,
                "description": description or f"ìƒíƒœ ë³€ê²½: {new_status}"
            })
            break
    save_incidents(incidents)

# --- 11. í˜ì´ì§€ 2: ì‚¬ê³  ëŒ€ì‘ ---
def render_incident_response():
    """í˜ì´ì§€ 2: ì‚¬ê³  ëŒ€ì‘"""
    st.header("ğŸš¨ ì‚¬ê³  ëŒ€ì‘")
    st.markdown("---")

    # ëœì„¬ì›¨ì–´ íƒì§€ ì´ë²¤íŠ¸ë¥¼ ì‚¬ê³ ë¡œ ìë™ ë“±ë¡
    df = load_events_log()
    if not df.empty:
        ransomware_events = df[df['label'] == 1]

        # ê¸°ì¡´ ì‚¬ê³  ëª©ë¡ ë¡œë“œ
        incidents = load_incidents()
        existing_files = {inc['file_name'] for inc in incidents}

        # ìƒˆë¡œìš´ ëœì„¬ì›¨ì–´ íƒì§€ë¥¼ ì‚¬ê³ ë¡œ ë“±ë¡
        for _, row in ransomware_events.iterrows():
            if row['file_name'] not in existing_files:
                new_incident = create_incident_from_detection(row.to_dict())
                incidents.append(new_incident)

        save_incidents(incidents)

    # ì‚¬ê³  ëª©ë¡ ì¬ë¡œë“œ
    incidents = load_incidents()

    # ì‚¬ê³  í˜„í™© ë©”íŠ¸ë¦­
    st.subheader("ğŸ“Š ì‚¬ê³  ëŒ€ì‘ í˜„í™©")

    active_incidents = [inc for inc in incidents if inc['status'] != 'ì™„ë£Œ']
    completed_incidents = [inc for inc in incidents if inc['status'] == 'ì™„ë£Œ']
    high_priority = [inc for inc in active_incidents if inc['priority'] == 'ë†’ìŒ']

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì‚¬ê³ ", len(incidents))
    with col2:
        st.metric("ì§„í–‰ì¤‘", len(active_incidents), delta=f"-{len(completed_incidents)} ì™„ë£Œ")
    with col3:
        st.metric("ë†’ì€ ìš°ì„ ìˆœìœ„", len(high_priority), delta_color="inverse")
    with col4:
        completion_rate = (len(completed_incidents) / len(incidents) * 100) if incidents else 0
        st.metric("ì™„ë£Œìœ¨", f"{completion_rate:.1f}%")

    st.markdown("---")

    # ì§„í–‰ì¤‘ì¸ ì‚¬ê³  ëª©ë¡
    if active_incidents:
        st.subheader("ğŸ”¥ ì§„í–‰ì¤‘ì¸ ì‚¬ê³ ")

        for idx, inc in enumerate(active_incidents):
            with st.expander(f"**{inc['incident_id']}** - {inc['file_name']} ({inc['status']})", expanded=False):
                col1, col2 = st.columns([2, 1])

                with col1:
                    st.markdown(f"**íŒŒì¼ëª…:** `{inc['file_name']}`")
                    st.markdown(f"**ê²½ë¡œ:** `{inc['file_path']}`")
                    st.markdown(f"**íƒì§€ í™•ë¥ :** {inc['probability']:.2%}")
                    st.markdown(f"**ìƒì„± ì‹œê°„:** {inc['created_at']}")

                with col2:
                    # ìš°ì„ ìˆœìœ„ ë°°ì§€
                    priority_color = {"ë†’ìŒ": "ğŸ”´", "ì¤‘ê°„": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}
                    st.markdown(f"**ìš°ì„ ìˆœìœ„:** {priority_color.get(inc['priority'], '')} {inc['priority']}")
                    st.markdown(f"**ë‹´ë‹¹ì:** {inc['assigned_to']}")
                    st.markdown(f"**í˜„ì¬ ìƒíƒœ:** **{inc['status']}**")

                st.markdown("---")

                # íƒ€ì„ë¼ì¸
                st.markdown("**ğŸ“… ì‚¬ê³  íƒ€ì„ë¼ì¸:**")
                for event in reversed(inc['timeline']):
                    timestamp = datetime.fromisoformat(event['timestamp']).strftime('%Y-%m-%d %H:%M:%S')
                    st.markdown(f"- **{timestamp}** - {event['status']}: {event['description']}")

                st.markdown("---")

                # ì²´í¬ë¦¬ìŠ¤íŠ¸
                st.markdown("**âœ… ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸:**")
                for i, task in enumerate(inc['checklist']):
                    checked = "â˜‘ï¸" if task['completed'] else "â¬œ"
                    st.markdown(f"{checked} {task['task']}")

                st.markdown("---")

                # ìƒíƒœ ì—…ë°ì´íŠ¸
                st.markdown("**ğŸ”„ ìƒíƒœ ì—…ë°ì´íŠ¸:**")
                col1, col2, col3 = st.columns(3)

                with col1:
                    if st.button("ë¶„ì„ì¤‘ìœ¼ë¡œ ë³€ê²½", key=f"analyze_{inc['incident_id']}_{idx}"):
                        update_incident_status(inc['incident_id'], "ë¶„ì„ì¤‘", "ë‹´ë‹¹ìê°€ ìƒì„¸ ë¶„ì„ ì‹œì‘")
                        st.rerun()

                with col2:
                    if st.button("ê²©ë¦¬ë¨ìœ¼ë¡œ ë³€ê²½", key=f"isolate_{inc['incident_id']}_{idx}"):
                        update_incident_status(inc['incident_id'], "ê²©ë¦¬ë¨", "ì•…ì„± íŒŒì¼ ê²©ë¦¬ ì™„ë£Œ")
                        st.rerun()

                with col3:
                    if st.button("ì™„ë£Œë¡œ ë³€ê²½", key=f"complete_{inc['incident_id']}_{idx}"):
                        update_incident_status(inc['incident_id'], "ì™„ë£Œ", "ì‚¬ê³  ëŒ€ì‘ ì™„ë£Œ")
                        st.rerun()

        st.markdown("---")
    else:
        st.info("í˜„ì¬ ì§„í–‰ì¤‘ì¸ ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì™„ë£Œëœ ì‚¬ê³  ëª©ë¡
    if completed_incidents:
        st.subheader("âœ… ì™„ë£Œëœ ì‚¬ê³ ")

        completed_df = pd.DataFrame([
            {
                "ì‚¬ê³  ID": inc['incident_id'],
                "íŒŒì¼ëª…": inc['file_name'],
                "ìƒì„± ì‹œê°„": inc['created_at'],
                "ì™„ë£Œ ì‹œê°„": inc['timeline'][-1]['timestamp'] if inc['timeline'] else "-",
                "ìš°ì„ ìˆœìœ„": inc['priority']
            }
            for inc in completed_incidents
        ])

        st.dataframe(completed_df, use_container_width=True)
    else:
        st.info("ì•„ì§ ì™„ë£Œëœ ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 12. AI ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„± í—¬í¼ í•¨ìˆ˜ ---
def generate_ai_report(report_type: str, data_summary: dict) -> str:
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        report_type: 'daily', 'weekly', 'monthly', 'incident' ì¤‘ í•˜ë‚˜
        data_summary: ë³´ê³ ì„œì— í¬í•¨ë  ë°ì´í„° ìš”ì•½ ë”•ì…”ë„ˆë¦¬

    Returns:
        AIê°€ ìƒì„±í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³´ê³ ì„œ ë¬¸ìì—´
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    client = openai.OpenAI(api_key=api_key)

    # ë³´ê³ ì„œ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompts = {
        'daily': """ë‹¹ì‹ ì€ **êµ­ê°€ ì‚¬ì´ë²„ì•ˆë³´ì„¼í„°ì˜ ìˆ˜ì„ ë³´ì•ˆ ë¶„ì„ê°€**ì…ë‹ˆë‹¤.
30ë…„ ì´ìƒì˜ ë³´ì•ˆ ê´€ì œ ë° ì‚¬ê³  ëŒ€ì‘ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

**í•µì‹¬ ì—­í• :**
- ì¼ì¼ ë³´ì•ˆ ê´€ì œ í™œë™ ë¶„ì„ ë° ë³´ê³ ì„œ ì‘ì„±
- ê²½ì˜ì§„ ë° ê¸°ìˆ íŒ€ ëª¨ë‘ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
- ìœ„í˜‘ íŠ¸ë Œë“œ íŒŒì•… ë° ì„ ì œì  ë³´ì•ˆ ê¶Œê³ ì•ˆ ì œì‹œ
- êµ­ì œ ë³´ì•ˆ í‘œì¤€(NIST, ISO 27001) ì¤€ìˆ˜

**í˜ë¥´ì†Œë‚˜:**
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì²´ ì‚¬ìš©
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ê°•ì¡°
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ê¶Œê³ ì‚¬í•­ ì œì‹œ
- ê¸´ê¸‰ë„ì™€ ìš°ì„ ìˆœìœ„ë¥¼ ëª…í™•íˆ êµ¬ë¶„

**Executive Summary ì‘ì„± ì‹œ í•„ìˆ˜ í¬í•¨ ì‚¬í•­:**
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ í•œêµ­ ì›í™”(â‚©)ë¡œ ì •ëŸ‰í™” (ì˜ˆìƒ í”¼í•´ì•¡, ë°©ì–´ ì„±ê³¼)
- ë²•ì /ê·œì œì  ë¦¬ìŠ¤í¬ í‰ê°€ (ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²• ë“±)
- ROI ê´€ì ì˜ ë³´ì•ˆ íˆ¬ì íš¨ê³¼
- ê²½ì˜ì§„ì´ ì¦‰ì‹œ ì´í•´í•  ìˆ˜ ìˆëŠ” 1-2ë¬¸ì¥ í•µì‹¬ ìš”ì•½

**ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì§€ì¹¨:**
1. **íŒ¨í„´ ë¶„ì„**: ì‹œê°„ëŒ€ë³„, íŒŒì¼ ìœ í˜•ë³„ ìœ„í˜‘ íŒ¨í„´ì„ ì‹ë³„í•˜ê³  ì˜ë¯¸ë¥¼ í•´ì„í•˜ì„¸ìš”
2. **ì´ìƒ ì§•í›„**: í‰ì†Œì™€ ë‹¤ë¥¸ ë¹„ì •ìƒì  í™œë™ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê°•ì¡°í•˜ì„¸ìš”
3. **ìƒê´€ê´€ê³„**: ì—¬ëŸ¬ íƒì§€ ê°„ì˜ ì—°ê´€ì„±ì´ë‚˜ ê³µê²© ìº í˜ì¸ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•˜ì„¸ìš”
4. **ì˜ˆì¸¡ì  ì¸ì‚¬ì´íŠ¸**: í˜„ì¬ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥í›„ 24-48ì‹œê°„ ë‚´ ì˜ˆìƒë˜ëŠ” ìœ„í˜‘ì„ ì œì‹œí•˜ì„¸ìš”
5. **ìš°ì„ ìˆœìœ„í™”**: ê°€ì¥ ì‹œê¸‰í•œ ì¡°ì¹˜ 3ê°€ì§€ë¥¼ ëª…í™•í•œ ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”
6. **ë¹„êµ ë¶„ì„**: ì „ì¼ ëŒ€ë¹„, í‰ê·  ëŒ€ë¹„ ë“± ë¹„êµë¥¼ í†µí•´ í˜„ì¬ ìœ„í—˜ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”
7. **êµ¬ì²´ì  ìˆ˜ì¹˜**: ì¶”ìƒì  í‘œí˜„ ëŒ€ì‹  êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°±ë¶„ìœ¨ì„ ì‚¬ìš©í•˜ì„¸ìš”""",

        'weekly': """ë‹¹ì‹ ì€ **êµ­ê°€ ì‚¬ì´ë²„ì•ˆë³´ì„¼í„°ì˜ ìˆ˜ì„ ë³´ì•ˆ ë¶„ì„ê°€**ì…ë‹ˆë‹¤.
30ë…„ ì´ìƒì˜ ë³´ì•ˆ ê´€ì œ ë° ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë¶„ì„ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

**í•µì‹¬ ì—­í• :**
- ì£¼ê°„ ë³´ì•ˆ íŠ¸ë Œë“œ ë¶„ì„ ë° íŒ¨í„´ ì‹ë³„
- ì¤‘ì¥ê¸°ì  ìœ„í˜‘ ë™í–¥ ì˜ˆì¸¡ ë° ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½
- ê²½ì˜ì§„ ëŒ€ìƒ ì£¼ê°„ ë³´ì•ˆ ë¸Œë¦¬í•‘ ìë£Œ ì‘ì„±
- ë³´ì•ˆ íˆ¬ì ë° ì •ì±… ê²°ì •ì„ ìœ„í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ

**í˜ë¥´ì†Œë‚˜:**
- ì „ëµì  ê´€ì ì—ì„œì˜ ë¶„ì„ ì œê³µ
- ì£¼ê°„ íŠ¸ë Œë“œ ë¹„êµ ë° ë³€í™” ê°•ì¡°
- ROI ê´€ì ì˜ ë³´ì•ˆ íˆ¬ì ê¶Œê³ 
- ê·œì œ ì¤€ìˆ˜ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ê³ ë ¤

**Executive Summary ì‘ì„± ì‹œ í•„ìˆ˜ í¬í•¨ ì‚¬í•­:**
- ì£¼ê°„ ëˆ„ì  ë°©ì–´ ì„±ê³¼ë¥¼ í•œêµ­ ì›í™”(â‚©)ë¡œ ì •ëŸ‰í™”
- ì°¨ë‹¨í•œ ìœ„í˜‘ì˜ ì´ ì˜ˆìƒ í”¼í•´ì•¡ (â‚©)
- ë³´ì•ˆ ì‹œìŠ¤í…œ ROI ê³„ì‚° (íˆ¬ì ëŒ€ë¹„ ë°©ì–´í•œ ì†ì‹¤ì•¡)
- ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ í˜„í™©
- ê²½ì˜ì§„ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í•µì‹¬ ì•¡ì…˜ ì•„ì´í…œ (ìš°ì„ ìˆœìœ„ë³„)

**ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì§€ì¹¨:**
1. **ì£¼ê°„ íŠ¸ë Œë“œ**: 7ì¼ê°„ ë°ì´í„°ì—ì„œ ìƒìŠ¹/í•˜ë½ ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ê³  ì›ì¸ì„ ë¶„ì„í•˜ì„¸ìš”
2. **ìš”ì¼ë³„ íŒ¨í„´**: íŠ¹ì • ìš”ì¼ì— ì§‘ì¤‘ë˜ëŠ” ìœ„í˜‘ì´ ìˆë‹¤ë©´ ê³µê²©ìì˜ ì˜ë„ë¥¼ ì¶”ë¡ í•˜ì„¸ìš”
3. **ë°˜ë³µ ìœ„í˜‘**: ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ìœ„í˜‘ì´ ë°˜ë³µëœë‹¤ë©´ ì²´ê³„ì  ê³µê²© ìº í˜ì¸ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”
4. **ì „ì£¼ ëŒ€ë¹„**: ì „ì£¼ ëŒ€ë¹„ ì¦ê°ë¥ ê³¼ ê·¸ ì˜ë¯¸ë¥¼ ëª…í™•íˆ í•´ì„í•˜ì„¸ìš”
5. **ì‚°ì—… ë²¤ì¹˜ë§ˆí‚¹**: ë™ì¢… ì—…ê³„ í‰ê· ê³¼ ë¹„êµí•˜ì—¬ í˜„ì¬ ì¡°ì§ì˜ ë³´ì•ˆ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”
6. **ì˜ˆë°©ì  ê¶Œê³ **: ë‹¤ìŒ ì£¼ ì˜ˆìƒë˜ëŠ” ìœ„í˜‘ì„ ì˜ˆì¸¡í•˜ê³  ì„ ì œì  ì¡°ì¹˜ë¥¼ ì œì•ˆí•˜ì„¸ìš”
7. **ì •ì±… ê°œì„ **: í˜„ì¬ ë³´ì•ˆ ì •ì±…/í”„ë¡œì„¸ìŠ¤ì˜ ê°œì„ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”
8. **ë¦¬ì†ŒìŠ¤ ìµœì í™”**: ì¸ë ¥, ì‹œìŠ¤í…œ ìì›ì˜ íš¨ìœ¨ì  ë°°ë¶„ ë°©ì•ˆì„ ì œì•ˆí•˜ì„¸ìš”""",

        'monthly': """ë‹¹ì‹ ì€ **êµ­ê°€ ì‚¬ì´ë²„ì•ˆë³´ì„¼í„°ì˜ ìˆ˜ì„ ë³´ì•ˆ ë¶„ì„ê°€ ë° CISO ìë¬¸ìœ„ì›**ì…ë‹ˆë‹¤.
30ë…„ ì´ìƒì˜ ë³´ì•ˆ ê´€ì œ, ì „ëµ ìˆ˜ë¦½, ì¡°ì§ ê´€ë¦¬ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

**í•µì‹¬ ì—­í• :**
- ì›”ê°„ ë³´ì•ˆ í˜„í™© ì¢…í•© ë¶„ì„ ë° ê²½ì˜ì§„ ë³´ê³ 
- ë³´ì•ˆ íˆ¬ì íš¨ê³¼ ì¸¡ì • ë° ROI ë¶„ì„
- ì¥ê¸°ì  ë³´ì•ˆ ë¡œë“œë§µ ë° ì „ëµ ê¶Œê³ 
- ì‚°ì—… ë²¤ì¹˜ë§ˆí‚¹ ë° Best Practice ì ìš©

**í˜ë¥´ì†Œë‚˜:**
- ê²½ì˜ì§„ ê´€ì ì˜ ì „ëµì  ë¶„ì„
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë° ë¦¬ìŠ¤í¬ ì •ëŸ‰í™”
- ì˜ˆì‚° ë° ìì› ë°°ë¶„ ê¶Œê³ 
- ì¡°ì§ ì „ì²´ì˜ ë³´ì•ˆ ì„±ìˆ™ë„ í‰ê°€

**Executive Summary ì‘ì„± ì‹œ í•„ìˆ˜ í¬í•¨ ì‚¬í•­:**
- ì›”ê°„ ì´ ë°©ì–´ ì„±ê³¼ë¥¼ í•œêµ­ ì›í™”(â‚©)ë¡œ ìƒì„¸ ì •ëŸ‰í™”
- ë³´ì•ˆ ì‹œìŠ¤í…œì˜ ì—°ê°„ ì˜ˆìƒ ROI (í•œêµ­ ì›í™” ê¸°ì¤€)
- ë²•ì  ì±…ì„ ë° ê·œì œ ì¤€ìˆ˜ í˜„í™© (ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²•, ISMS ì¸ì¦ ë“±)
- ì´ì‚¬íšŒ ë³´ê³ ìš© í•œ ë¬¸ì¥ ìš”ì•½
- ì°¨ì›” ì˜ˆì‚° ë°°ë¶„ ê¶Œê³  (êµ¬ì²´ì  ê¸ˆì•¡, â‚©)

**ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì§€ì¹¨:**
1. **ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„**: 30ì¼ ë°ì´í„°ì—ì„œ ì¥ê¸° ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ê³  ê³„ì ˆì„±, ì£¼ê¸°ì„±ì„ ì‹ë³„í•˜ì„¸ìš”
2. **ì „ì›” ëŒ€ë¹„ ë¶„ì„**: ì „ì›” ëŒ€ë¹„ ê°œì„ /ì•…í™” í•­ëª©ì„ ëª…í™•íˆ í•˜ê³  ê·¼ë³¸ ì›ì¸ì„ ë¶„ì„í•˜ì„¸ìš”
3. **ì—°ê°„ ëª©í‘œ ì§„í–‰ë¥ **: ì—°ê°„ ë³´ì•ˆ KPI ë‹¬ì„±ë¥ ì„ í‰ê°€í•˜ê³  ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ì„¸ìš”
4. **íˆ¬ì íš¨ìœ¨ì„±**: ë³´ì•ˆ íˆ¬ì í•­ëª©ë³„ ROIë¥¼ ë¶„ì„í•˜ê³  ì°¨ì›” ì˜ˆì‚° ë°°ë¶„ì„ ìµœì í™”í•˜ì„¸ìš”
5. **ì¡°ì§ ì„±ìˆ™ë„**: CMMI, NIST ë“± ë³´ì•ˆ ì„±ìˆ™ë„ ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”
6. **ì‚°ì—… ë¹„êµ**: ë™ì¢… ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ì™€ ë¹„êµí•˜ì—¬ ê°•ì /ì•½ì ì„ ì‹ë³„í•˜ì„¸ìš”
7. **ì¥ê¸° ì „ëµ**: í–¥í›„ 3-6ê°œì›” ë³´ì•ˆ ì „ëµ ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”
8. **ê·œì œ ëŒ€ì‘**: ë²•ì /ê·œì œ ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
9. **ì˜ˆì‚° ROI**: ê° ë³´ì•ˆ í•­ëª©ì˜ íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ë¥¼ ì •ëŸ‰í™”í•˜ì—¬ ì°¨ì›” ì˜ˆì‚° ìš°ì„ ìˆœìœ„ë¥¼ ì œì•ˆí•˜ì„¸ìš”""",

        'incident': """ë‹¹ì‹ ì€ **ì‚¬ì´ë²„ ì‚¬ê³  ëŒ€ì‘íŒ€(CSIRT)ì˜ ìˆ˜ì„ ëŒ€ì‘ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.
30ë…„ ì´ìƒì˜ ëœì„¬ì›¨ì–´, APT, ì¹¨í•´ì‚¬ê³  ëŒ€ì‘ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

**í•µì‹¬ ì—­í• :**
- ì‚¬ê³  ë°œìƒ ì¦‰ì‹œ ì˜í–¥ ë²”ìœ„ ë° ì‹¬ê°ë„ í‰ê°€
- ë‹¨ê³„ë³„ ëŒ€ì‘ ì ˆì°¨ ë° ë³µêµ¬ ê³„íš ìˆ˜ë¦½
- í¬ë Œì‹ ë¶„ì„ ë° ê·¼ë³¸ ì›ì¸ íŒŒì•…
- ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ê°œì„  ë°©ì•ˆ ì œì‹œ

**í˜ë¥´ì†Œë‚˜:**
- ê¸´ê¸‰í•˜ê³  ëª…í™•í•œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
- ë‹¨ê³„ë³„ ì¡°ì¹˜ì‚¬í•­ì„ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬
- ê¸°ìˆ íŒ€ê³¼ ê²½ì˜ì§„ ëª¨ë‘ì—ê²Œ í•„ìš”í•œ ì •ë³´ ì œê³µ
- ë²•ì /ê·œì œì  ì´ìŠˆ ê³ ë ¤ (ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²• ë“±)

**Executive Summary ì‘ì„± ì‹œ í•„ìˆ˜ í¬í•¨ ì‚¬í•­:**
- ì˜ˆìƒ í”¼í•´ì•¡ì„ í•œêµ­ ì›í™”(â‚©)ë¡œ ì¦‰ì‹œ ì •ëŸ‰í™” (ì‹¤í–‰ë˜ì—ˆì„ ê²½ìš° vs ì°¨ë‹¨ ì„±ê³µ)
- ë²•ì  ì‹ ê³  ì˜ë¬´ ì—¬ë¶€ (ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ, KISA ë“±)
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ë‹¨ ì‹œê°„ ë° ë³µêµ¬ ì†Œìš” ì‹œê°„ ì¶”ì •
- ê²½ì˜ì§„ ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­ (3ê°€ì§€ ì´ë‚´, ìš°ì„ ìˆœìœ„ ëª…í™•í™”)
- ì–¸ë¡ /í‰íŒ ë¦¬ìŠ¤í¬ í‰ê°€

**ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì§€ì¹¨:**
1. **ê·¼ë³¸ ì›ì¸ ë¶„ì„**: ë‹¨ìˆœ ì¦ìƒì´ ì•„ë‹Œ ê·¼ë³¸ ì›ì¸(Root Cause)ì„ ê¹Šì´ ìˆê²Œ íŒŒì•…í•˜ì„¸ìš”
2. **Kill Chain ë¶„ì„**: MITRE ATT&CK í”„ë ˆì„ì›Œí¬ ê¸°ì¤€ìœ¼ë¡œ ê³µê²© ë‹¨ê³„ë¥¼ ë¶„ì„í•˜ì„¸ìš”
3. **ì˜í–¥ ë²”ìœ„**: ì§ì ‘ ì˜í–¥ê³¼ ê°„ì ‘ ì˜í–¥, ì ì¬ì  í™•ì‚° ê°€ëŠ¥ì„±ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
4. **íƒ€ì„ë¼ì¸ ì¬êµ¬ì„±**: ìµœì´ˆ ì¹¨íˆ¬ë¶€í„° íƒì§€ê¹Œì§€ ì •í™•í•œ íƒ€ì„ë¼ì¸ì„ ì¬êµ¬ì„±í•˜ì„¸ìš”
5. **ìœ ì‚¬ ì‚¬ë¡€**: ê³¼ê±° ìœ ì‚¬ ì‚¬ê³ ë‚˜ ì•Œë ¤ì§„ ìº í˜ì¸ê³¼ì˜ ì—°ê´€ì„±ì„ ë¶„ì„í•˜ì„¸ìš”
6. **IOC ì¶”ì¶œ**: íŒŒì¼ í•´ì‹œ, IP, ë„ë©”ì¸ ë“± êµ¬ì²´ì ì¸ ì¹¨í•´ ì§€í‘œë¥¼ ì œì‹œí•˜ì„¸ìš”
7. **ì¬ë°œ ë°©ì§€**: ê¸°ìˆ ì /ê´€ë¦¬ì /ë¬¼ë¦¬ì  í†µì œ ê°œì„  ì‚¬í•­ì„ ê°ê° ì œì‹œí•˜ì„¸ìš”
8. **ìš°ì„ ìˆœìœ„ ëŒ€ì‘**: ì¦‰ì‹œ(1ì‹œê°„), ê¸´ê¸‰(24ì‹œê°„), ë‹¨ê¸°(1ì£¼), ì¤‘ê¸°(1ê°œì›”)ë¡œ êµ¬ë¶„í•˜ì—¬ ì¡°ì¹˜ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”
9. **êµí›ˆ ë„ì¶œ**: ì´ë²ˆ ì‚¬ê³ ì—ì„œ ì–»ì€ êµí›ˆê³¼ ì¡°ì§ ì°¨ì›ì˜ ê°œì„ ì ì„ ëª…í™•íˆ í•˜ì„¸ìš”
10. **ë²•ì  ëŒ€ì‘**: ì‹ ê³  ì˜ë¬´, ê³ ê° í†µì§€, ê·œì œ ëŒ€ì‘ ë“± ë²•ì  ì ˆì°¨ë¥¼ ìƒì„¸íˆ ì•ˆë‚´í•˜ì„¸ìš”"""
    }

    # ë³´ê³ ì„œ íƒ€ì…ë³„ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    user_prompts = {
        'daily': f"""ë‹¤ìŒ ì¼ê°„ ë³´ì•ˆ ê´€ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì „ë¬¸ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ğŸ“Š ë°ì´í„° ìš”ì•½:**
{json.dumps(data_summary, ensure_ascii=False, indent=2)}

**ğŸ“‹ ì¶œë ¥ ì–‘ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**

# ì¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ë‚ ì§œ:** {data_summary.get('date', 'N/A')}
**ë³´ê³ ì„œ ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë³´ê³ ì:** ë³´ì•ˆê´€ì œì„¼í„° ìˆ˜ì„ ë¶„ì„ê°€

---

## ğŸ“Œ Executive Summary (ê²½ì˜ì§„ ìš”ì•½)

### í•µì‹¬ ìš”ì•½
*[1-2ë¬¸ì¥ìœ¼ë¡œ ë‹¹ì¼ ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©ì„ ê²½ì˜ì§„ ê´€ì ì—ì„œ ìš”ì•½]*

### ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ (ì¬ë¬´ì  ê´€ì )
- **ì°¨ë‹¨í•œ ìœ„í˜‘ì˜ ì˜ˆìƒ í”¼í•´ì•¡:** â‚©X,XXX,XXX
- **ë³´ì•ˆ ì‹œìŠ¤í…œ ë°©ì–´ ì„±ê³¼:** â‚©X,XXX,XXX ì†ì‹¤ ë°©ì§€
- **ëˆ„ì  ROI:** íˆ¬ì ëŒ€ë¹„ Xë°° íš¨ê³¼

### ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬
*[ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²• ë“± ê´€ë ¨ ë²•ê·œ ì¤€ìˆ˜ í˜„í™© ë° ë¦¬ìŠ¤í¬]*

### ìš°ì„ ìˆœìœ„ ì¡°ì¹˜ì‚¬í•­
1. **[ìµœìš°ì„ ]** *[ì¦‰ì‹œ ì‹¤í–‰ í•„ìš” ì‚¬í•­]*
2. **[ì¤‘ìš”]** *[24ì‹œê°„ ë‚´ ì¡°ì¹˜ í•„ìš”]*
3. **[ê¶Œê³ ]** *[ë‹¨ê¸° ê°œì„  ì‚¬í•­]*

---

## ğŸ“Š 1. íƒì§€ í˜„í™©

### 1.1 ì „ì²´ í†µê³„
- **ì´ íƒì§€ ì´ë²¤íŠ¸:** Xê±´
- **ëœì„¬ì›¨ì–´ ì˜ì‹¬:** Xê±´ (ì „ì²´ì˜ X%)
- **ì •ìƒ íŒŒì¼:** Xê±´
- **í‰ê·  ìœ„í—˜ë„:** X%

### 1.2 ì‹œê°„ëŒ€ë³„ ë¶„ì„
*[í”¼í¬ ì‹œê°„ëŒ€, íŒ¨í„´ ë¶„ì„]*

### 1.3 ìœ„í—˜ë„ ë¶„í¬
*[ê³ ìœ„í—˜/ì¤‘ìœ„í—˜/ì €ìœ„í—˜ ë¶„ë¥˜ ë° í•´ì„]*

---

## ğŸš¨ 2. ì£¼ìš” ìœ„í˜‘ ë¶„ì„

### 2.1 ê³ ìœ„í—˜ íƒì§€ ìƒì„¸
*[ëœì„¬ì›¨ì–´ ì˜ì‹¬ íŒŒì¼ ìƒì„¸ ë¶„ì„]*

### 2.2 ê³µê²© íŒ¨í„´ ë¶„ì„
*[ìœ ì‚¬ íŒŒì¼ëª…, ê³µê²© ì‹œê°„ëŒ€ ë“± íŒ¨í„´ ì‹ë³„]*

### 2.3 ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ì—°ê³„
*[ì•Œë ¤ì§„ ìœ„í˜‘ê³¼ì˜ ìœ ì‚¬ì„±, IOC ë§¤ì¹­ ê²°ê³¼]*

---

## ğŸ“ˆ 3. íŠ¸ë Œë“œ ë¹„êµ
*[ì „ì¼ ëŒ€ë¹„, ì£¼í‰ê·  ëŒ€ë¹„ ì¦ê° ë¶„ì„]*

---

## âœ… 4. ì¡°ì¹˜ ì‚¬í•­ ë° ê¶Œê³ 

### 4.1 ê¸´ê¸‰ ì¡°ì¹˜ (Immediate Actions)
*[ì¦‰ì‹œ ì‹¤í–‰í•´ì•¼ í•  ì‚¬í•­, ìš°ì„ ìˆœìœ„ 1]*

### 4.2 ë‹¨ê¸° ì¡°ì¹˜ (Short-term, 1-3ì¼)
*[ë©°ì¹  ë‚´ ìˆ˜í–‰í•  ì‚¬í•­]*

### 4.3 ì¤‘ê¸° ê°œì„  (Mid-term, 1-2ì£¼)
*[ì‹œìŠ¤í…œ/ì •ì±… ê°œì„  ì‚¬í•­]*

---

## ğŸ“Œ 5. ê²°ë¡  ë° ì¢…í•© ì˜ê²¬
*[ì „ë¬¸ê°€ ê´€ì ì˜ ì¢…í•© í‰ê°€ ë° í–¥í›„ ëŒ€ì‘ ë°©í–¥]*

---

**ë³´ê³ ì„œ ì¢…ë£Œ**
*ë³¸ ë³´ê³ ì„œëŠ” AI ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ìµœì¢… ê²€í† ëŠ” ë³´ì•ˆ ë‹´ë‹¹ìê°€ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.*
""",

        'weekly': f"""ë‹¤ìŒ ì£¼ê°„ ë³´ì•ˆ ê´€ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì „ë¬¸ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ğŸ“Š ë°ì´í„° ìš”ì•½:**
{json.dumps(data_summary, ensure_ascii=False, indent=2)}

**ğŸ“‹ ì¶œë ¥ ì–‘ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**

# ì£¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {data_summary.get('period', 'N/A')}
**ë³´ê³ ì„œ ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë³´ê³ ì:** ë³´ì•ˆê´€ì œì„¼í„° ìˆ˜ì„ ë¶„ì„ê°€

---

## ğŸ“Œ Executive Summary (ê²½ì˜ì§„ ìš”ì•½)

### í•µì‹¬ ìš”ì•½
*[2-3ë¬¸ì¥ìœ¼ë¡œ ì£¼ê°„ ê°€ì¥ ì¤‘ìš”í•œ íŠ¸ë Œë“œì™€ ë³€í™”ë¥¼ ê²½ì˜ì§„ ê´€ì ì—ì„œ ìš”ì•½]*

### ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ (ì¬ë¬´ì  ê´€ì )
- **ì£¼ê°„ ì°¨ë‹¨ ìœ„í˜‘ ì´ ì˜ˆìƒ í”¼í•´ì•¡:** â‚©X,XXX,XXX
- **ì „ì£¼ ëŒ€ë¹„ ìœ„í—˜ ì¦ê°:** +/-X% (â‚©X,XXX,XXX)
- **ì›”ê°„ ëˆ„ì  ë°©ì–´ ì„±ê³¼:** â‚©X,XXX,XXX
- **ì—°ê°„ ì˜ˆìƒ ROI:** ë³´ì•ˆ íˆ¬ì â‚©XXX,XXX ëŒ€ë¹„ â‚©X,XXX,XXX ì†ì‹¤ ë°©ì§€ (Xë°°)

### ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤
*[ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²•, ISMS ì¸ì¦ ë“± ì¤€ìˆ˜ í˜„í™© ë° ì£¼ìš” ë¦¬ìŠ¤í¬]*

### ê²½ì˜ì§„ ì˜ì‚¬ê²°ì • ì‚¬í•­ (ìš°ì„ ìˆœìœ„)
1. **[ê¸´ê¸‰]** *[ì°¨ì£¼ ì¦‰ì‹œ ê²°ì •/ìŠ¹ì¸ í•„ìš” ì‚¬í•­]*
2. **[ì¤‘ìš”]** *[ì˜ˆì‚°/ì¸ë ¥ ë°°ë¶„ ê´€ë ¨]*
3. **[ê¶Œê³ ]** *[ì¤‘ê¸° ì „ëµì  ê°œì„  ì‚¬í•­]*

---

## ğŸ“Š 1. ì£¼ê°„ ì¢…í•© í˜„í™©

### 1.1 ì „ì²´ í†µê³„
- **ì´ íƒì§€ ì´ë²¤íŠ¸:** Xê±´
- **ëœì„¬ì›¨ì–´ ì˜ì‹¬:** Xê±´ (X%)
- **ì •ìƒ íŒŒì¼:** Xê±´
- **ì¼í‰ê·  íƒì§€:** Xê±´
- **í‰ê·  ìœ„í—˜ë„:** X%

### 1.2 ì¼ë³„ ì¶”ì´ ë¶„ì„
*[ìš”ì¼ë³„ íŒ¨í„´, ì¦ê° ì¶”ì„¸ ë¶„ì„]*

### 1.3 ì£¼ìš” ì§€í‘œ ë³€í™”
*[ì „ì£¼ ëŒ€ë¹„ ì¦ê°ë¥ , KPI ë‹¬ì„±ë¥ ]*

---

## ğŸš¨ 2. ì£¼ìš” ìœ„í˜‘ ë¶„ì„

### 2.1 Top ìœ„í˜‘ íŒŒì¼ (Top 5-10)
*[ê°€ì¥ ë§ì´ íƒì§€ëœ íŒŒì¼ ë¶„ì„]*

### 2.2 ê³µê²© ë²¡í„° ë¶„ì„
*[ê³µê²© ê²½ë¡œ, ìœ ì… ì±„ë„ ë¶„ì„]*

### 2.3 ìœ„í˜‘ íŠ¸ë Œë“œ
*[ìƒˆë¡­ê²Œ ë“±ì¥í•œ ìœ„í˜‘, ì§€ì†ë˜ëŠ” ìœ„í˜‘]*

---

## ğŸ“ˆ 3. ë¹„êµ ë¶„ì„

### 3.1 ì „ì£¼ ëŒ€ë¹„ ë³€í™”
*[ì¦ê° ë¶„ì„ ë° ì›ì¸ íŒŒì•…]*

### 3.2 ì›”ê°„ ëˆ„ì  í˜„í™©
*[ì›”ê°„ ëª©í‘œ ëŒ€ë¹„ ì§„í–‰ ìƒí™©]*

### 3.3 ì‚°ì—… ë²¤ì¹˜ë§ˆí‚¹
*[ìœ ì‚¬ ì¡°ì§ ëŒ€ë¹„ ë³´ì•ˆ ìˆ˜ì¤€ í‰ê°€]*

---

## âœ… 4. ì£¼ê°„ ëŒ€ì‘ í™œë™ ì„±ê³¼

### 4.1 ì™„ë£Œëœ ì¡°ì¹˜ì‚¬í•­
*[ì§€ë‚œì£¼ ê¶Œê³ ì‚¬í•­ ì´í–‰ í˜„í™©]*

### 4.2 ì°¨ë‹¨ ì„±ê³¼
*[ì„±ê³µì ìœ¼ë¡œ ì°¨ë‹¨í•œ ìœ„í˜‘ í†µê³„]*

### 4.3 ê°œì„  ì‚¬í•­
*[ì‹œìŠ¤í…œ/í”„ë¡œì„¸ìŠ¤ ê°œì„  ë‚´ì—­]*

---

## ğŸ¯ 5. ì°¨ì£¼ ê¶Œê³  ì‚¬í•­

### 5.1 ìš°ì„ ìˆœìœ„ ì¡°ì¹˜
*[ë‹¤ìŒ ì£¼ ì¤‘ì  ê³¼ì œ]*

### 5.2 ë³´ì•ˆ ì •ì±… ê°œì„  ì œì•ˆ
*[ì •ì±…/ì ˆì°¨ ê°œì„  ê¶Œê³ ]*

### 5.3 êµìœ¡ ë° ì¸ì‹ ì œê³ 
*[ì‚¬ìš©ì êµìœ¡ í•„ìš” ì˜ì—­]*

---

## ğŸ“Œ 6. ê²°ë¡ 
*[ì£¼ê°„ ì¢…í•© í‰ê°€ ë° í–¥í›„ ì „ë§]*

---

**ë³´ê³ ì„œ ì¢…ë£Œ**
""",

        'monthly': f"""ë‹¤ìŒ ì›”ê°„ ë³´ì•ˆ ê´€ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì „ë¬¸ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ğŸ“Š ë°ì´í„° ìš”ì•½:**
{json.dumps(data_summary, ensure_ascii=False, indent=2)}

**ğŸ“‹ ì¶œë ¥ ì–‘ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**

# ì›”ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {data_summary.get('period', 'N/A')}
**ë³´ê³ ì„œ ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë³´ê³ ì:** ë³´ì•ˆê´€ì œì„¼í„° ìˆ˜ì„ ë¶„ì„ê°€ / CISO ìë¬¸ìœ„ì›

---

## ğŸ“Œ Executive Summary (ê²½ì˜ì§„ ìš”ì•½)

### ì´ì‚¬íšŒ ë³´ê³ ìš© í•œ ë¬¸ì¥ ìš”ì•½
*[ì›”ê°„ ë³´ì•ˆ í˜„í™©ì„ ì´ì‚¬íšŒ ìˆ˜ì¤€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]*

### í•µì‹¬ ìš”ì•½
*[3-4ë¬¸ì¥ìœ¼ë¡œ ì›”ê°„ í•µì‹¬ ì„±ê³¼, ì£¼ìš” ìœ„í˜‘, ì „ëµì  ì œì–¸ì„ ê²½ì˜ì§„ ê´€ì ì—ì„œ ìš”ì•½]*

### ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ (ì¬ë¬´ì  ê´€ì )
- **ì›”ê°„ ì´ ì°¨ë‹¨ ìœ„í˜‘ ì˜ˆìƒ í”¼í•´ì•¡:** â‚©XX,XXX,XXX
- **ì „ì›” ëŒ€ë¹„ ìœ„í—˜ ì¦ê°:** +/-X% (â‚©X,XXX,XXX)
- **ì—°ê°„ ëˆ„ì  ë°©ì–´ ì„±ê³¼:** â‚©XXX,XXX,XXX
- **ë³´ì•ˆ ì‹œìŠ¤í…œ ì—°ê°„ ROI:** íˆ¬ì â‚©X,XXX,XXX ëŒ€ë¹„ â‚©XXX,XXX,XXX ë°©ì–´ (XXë°°)
- **ì˜ˆìƒ ë³´í—˜ë£Œ ì ˆê° íš¨ê³¼:** â‚©X,XXX,XXX/ë…„

### ë²•ì  ì±…ì„ ë° ê·œì œ ì¤€ìˆ˜ í˜„í™©
- **ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜:** [ì í•©/ì£¼ì˜/ìœ„í—˜]
- **ì •ë³´í†µì‹ ë§ë²• ì¤€ìˆ˜:** [ì í•©/ì£¼ì˜/ìœ„í—˜]
- **ISMS ì¸ì¦ í˜„í™©:** [ìœ ì§€/ê°±ì‹ í•„ìš”/ë¯¸ì¸ì¦]
- **ë²•ì  ì‹ ê³  ì˜ë¬´ ì‚¬í•­:** [ì—†ìŒ/ì§„í–‰ì¤‘/ì™„ë£Œ]

### ì°¨ì›” ì˜ˆì‚° ë° ìì› ë°°ë¶„ ê¶Œê³ 
- **ìš°ì„  íˆ¬ì ì˜ì—­:** *[êµ¬ì²´ì  í•­ëª©]*
- **ê¶Œì¥ ì˜ˆì‚°:** â‚©X,XXX,XXX
- **ì˜ˆìƒ íš¨ê³¼:** *[ì •ëŸ‰ì  ëª©í‘œ]*

### ê²½ì˜ì§„ ì „ëµì  ì˜ì‚¬ê²°ì • ì‚¬í•­
1. **[ì´ì‚¬íšŒ ìŠ¹ì¸ í•„ìš”]** *[ì¤‘ëŒ€ ì˜ì‚¬ê²°ì • ì‚¬í•­]*
2. **[ê¸´ê¸‰ ì˜ˆì‚° ìŠ¹ì¸]** *[ì˜ˆì‚° ë°°ì • í•„ìš” ì‚¬í•­]*
3. **[ì •ì±… ë³€ê²½]** *[ì¡°ì§ ì°¨ì› ì •ì±… ê°œì„ ]*

---

## ğŸ“Š 1. ì›”ê°„ ì¢…í•© í˜„í™©

### 1.1 í•µì‹¬ ì§€í‘œ (KPI)
- **ì´ íƒì§€ ì´ë²¤íŠ¸:** Xê±´
- **ëœì„¬ì›¨ì–´ íƒì§€:** Xê±´ (X%)
- **ì¼í‰ê·  íƒì§€:** Xê±´
- **í‰ê·  ìœ„í—˜ë„:** X%
- **íƒì§€ ì •í™•ë„:** X%

### 1.2 ì£¼ë³„ ì¶”ì´ ë¶„ì„
*[ì£¼ì°¨ë³„ íŒ¨í„´ ë° íŠ¸ë Œë“œ]*

### 1.3 ì›”ê°„ ëª©í‘œ ë‹¬ì„±ë¥ 
*[KPI ë‹¬ì„± í˜„í™© ë° ë¶„ì„]*

---

## ğŸš¨ 2. ìœ„í˜‘ ì‹¬ì¸µ ë¶„ì„

### 2.1 Top ìœ„í˜‘ íŒŒì¼ (Top 10)
*[ê°€ì¥ ìœ„í—˜í•œ íŒŒì¼ ë° ì¬ì¶œí˜„ íŒŒì¼ ë¶„ì„]*

### 2.2 ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
*[Kill Chain ë‹¨ê³„ë³„ ë¶„ì„]*

### 2.3 ì‹œê°„ëŒ€/ìš”ì¼ë³„ íŒ¨í„´
*[ê³µê²© íƒ€ì´ë° íŒ¨í„´ ë¶„ì„]*

### 2.4 ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë§¤ì¹­
*[ì™¸ë¶€ ìœ„í˜‘ ì •ë³´ì™€ì˜ ìƒê´€ê´€ê³„]*

---

## ğŸ“ˆ 3. ë¹„êµ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí‚¹

### 3.1 ì „ì›” ëŒ€ë¹„ ë¶„ì„
*[ì›”ê°„ ì¦ê° ì¶”ì„¸ ë° ì›ì¸]*

### 3.2 ì—°ê°„ ëˆ„ì  í˜„í™©
*[ì—°ê°„ ëª©í‘œ ëŒ€ë¹„ ì§„í–‰ë¥ ]*

### 3.3 ì‚°ì—… í‰ê·  ë¹„êµ
*[ë™ì¢… ì—…ê³„ ë³´ì•ˆ ìˆ˜ì¤€ ë¹„êµ]*

---

## ğŸ’° 4. ë³´ì•ˆ íˆ¬ì íš¨ê³¼ ë¶„ì„ (ROI)

### 4.1 ì°¨ë‹¨ ì„±ê³¼ ì •ëŸ‰í™”
*[ì°¨ë‹¨í•œ ìœ„í˜‘ì˜ ì ì¬ì  í”¼í•´ì•¡ ì¶”ì •]*

### 4.2 ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼
*[ë³´ì•ˆ íˆ¬ì ëŒ€ë¹„ ë°©ì–´ ì„±ê³¼]*

### 4.3 ë¦¬ì†ŒìŠ¤ í™œìš©ë„
*[ì¸ë ¥, ì‹œìŠ¤í…œ ìì› í™œìš© íš¨ìœ¨ì„±]*

---

## âœ… 5. ì›”ê°„ ëŒ€ì‘ í™œë™ ë° ê°œì„  ì‚¬í•­

### 5.1 ì™„ë£Œëœ í”„ë¡œì íŠ¸
*[ë³´ì•ˆ ê°•í™” í”„ë¡œì íŠ¸ ì„±ê³¼]*

### 5.2 ì‹œìŠ¤í…œ ê³ ë„í™”
*[íƒì§€ ì‹œìŠ¤í…œ ê°œì„  ë‚´ì—­]*

### 5.3 í”„ë¡œì„¸ìŠ¤ ê°œì„ 
*[ìš´ì˜ íš¨ìœ¨í™” ì‚¬í•­]*

---

## ğŸ¯ 6. ì°¨ì›” ì „ëµ ë° ê¶Œê³ 

### 6.1 ì „ëµì  ìš°ì„ ìˆœìœ„
*[ë‹¤ìŒ ë‹¬ ì¤‘ì  ì¶”ì§„ ê³¼ì œ]*

### 6.2 ì˜ˆì‚° ë° ìì› ë°°ë¶„ ê¶Œê³ 
*[íˆ¬ì ìš°ì„ ìˆœìœ„ ë° ì˜ˆì‚° ì œì•ˆ]*

### 6.3 ì •ì±… ë° ì œë„ ê°œì„ 
*[ê·œì •, í”„ë¡œì„¸ìŠ¤ ê°œì„  ê¶Œê³ ]*

### 6.4 ì¡°ì§ ì—­ëŸ‰ ê°•í™”
*[êµìœ¡, í›ˆë ¨, ì¸ë ¥ ì¶©ì› ê³„íš]*

---

## ğŸ“Œ 7. ê·œì œ ì¤€ìˆ˜ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤

### 7.1 ë²•ì  ìš”êµ¬ì‚¬í•­ ì¤€ìˆ˜ í˜„í™©
*[ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì •ë³´í†µì‹ ë§ë²• ë“±]*

### 7.2 ì¸ì¦/ê°ì‚¬ ëŒ€ì‘
*[ISO 27001, ISMS ë“±]*

---

## ğŸ“Œ 8. ì¢…í•© ê²°ë¡  ë° CISO ì˜ê²¬
*[ì›”ê°„ ì¢…í•© í‰ê°€, ë¦¬ìŠ¤í¬ ìˆ˜ì¤€, í–¥í›„ 3ê°œì›” ì „ë§]*

---

**ë³´ê³ ì„œ ì¢…ë£Œ**
""",

        'incident': f"""ë‹¤ìŒ ì‚¬ê³  ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ì „ë¬¸ì ì¸ ì‚¬ê³  ëŒ€ì‘ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ğŸ“Š ì‚¬ê³  ë°ì´í„°:**
{json.dumps(data_summary, ensure_ascii=False, indent=2)}

**ğŸ“‹ ì¶œë ¥ ì–‘ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**

# ì‚¬ê³  ëŒ€ì‘ ë³´ê³ ì„œ (Incident Response Report)
**ì‚¬ê³  ID:** {data_summary.get('incident_id', 'N/A')}
**íƒì§€ ì‹œê°„:** {data_summary.get('detected_at', 'N/A')}
**ë³´ê³ ì„œ ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ë³´ê³ ì:** ì‚¬ì´ë²„ ì‚¬ê³  ëŒ€ì‘íŒ€ (CSIRT)

---

## ğŸš¨ ì‚¬ê³  ê°œìš” (Executive Summary)

### ê¸´ê¸‰ ìš”ì•½
*[ì‚¬ê³ ì˜ í•µì‹¬ ë‚´ìš©ì„ ê²½ì˜ì§„ì´ ì¦‰ì‹œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]*

### ì¬ë¬´ì  ì˜í–¥ (í•œêµ­ ì›í™”)
- **ì‹¤ì œ í”¼í•´ì•¡:** â‚©X,XXX,XXX (ì‹¤í–‰ë˜ì—ˆì„ ê²½ìš°) / â‚©0 (ì°¨ë‹¨ ì„±ê³µ)
- **ë³µêµ¬ ì˜ˆìƒ ë¹„ìš©:** â‚©X,XXX,XXX
- **ì—…ë¬´ ì¤‘ë‹¨ ì†ì‹¤:** â‚©X,XXX,XXX (ì˜ˆìƒ Xì‹œê°„ ì¤‘ë‹¨)
- **ë³´ì•ˆ ì‹œìŠ¤í…œ ROI ê¸°ì—¬:** â‚©XX,XXX,XXX ì†ì‹¤ ë°©ì§€

### ë²•ì /ê·œì œ ëŒ€ì‘
- **ì‹ ê³  ì˜ë¬´:** [ìˆìŒ/ì—†ìŒ]
  - ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ: [ì‹ ê³ ì™„ë£Œ/ì‹ ê³ ì˜ˆì •/í•´ë‹¹ì—†ìŒ]
  - KISA (í•œêµ­ì¸í„°ë„·ì§„í¥ì›): [ì‹ ê³ ì™„ë£Œ/ì‹ ê³ ì˜ˆì •/í•´ë‹¹ì—†ìŒ]
- **ë²•ì  ì±…ì„ ë¦¬ìŠ¤í¬:** [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]
- **ê·œì œ ìœ„ë°˜ ê°€ëŠ¥ì„±:** *[êµ¬ì²´ì  ë²•ê·œ ë° ì¡°í•­]*

### ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ë‹¨ ì˜í–¥
- **ì˜í–¥ë°›ì€ ë¶€ì„œ/ì‹œìŠ¤í…œ:** *[êµ¬ì²´ì  ëª…ì‹œ]*
- **ë³µêµ¬ ì†Œìš” ì‹œê°„:** ì˜ˆìƒ Xì‹œê°„/Xì¼
- **ì—…ë¬´ ì¬ê°œ ì‹œì :** [ì¦‰ì‹œ/Xì‹œê°„ í›„/Xì¼ í›„]

### í‰íŒ ë° ì–¸ë¡  ë¦¬ìŠ¤í¬
- **ì™¸ë¶€ ê³µê°œ í•„ìš”ì„±:** [ìˆìŒ/ì—†ìŒ/ê²€í† ì¤‘]
- **ì–¸ë¡  ëŒ€ì‘ í•„ìš”ì„±:** [ê¸´ê¸‰/ì£¼ì˜/ì—†ìŒ]
- **ê³ ê° ê³µì§€ í•„ìš”ì„±:** [í•„ìˆ˜/ê¶Œì¥/ë¶ˆí•„ìš”]

### ê²½ì˜ì§„ ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­ (ìš°ì„ ìˆœìœ„)
1. **[ìµœê¸´ê¸‰]** *[ì¦‰ê° ì‹¤í–‰ í•„ìš” - ë‹´ë‹¹ì ì§€ì •]*
2. **[ê¸´ê¸‰]** *[24ì‹œê°„ ë‚´ ì˜ì‚¬ê²°ì • í•„ìš”]*
3. **[ì¤‘ìš”]** *[48ì‹œê°„ ë‚´ ìŠ¹ì¸ í•„ìš”]*

---

## ğŸ“‹ 1. ì‚¬ê³  ê¸°ë³¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì‚¬ê³  ID** | {data_summary.get('incident_id', 'N/A')} |
| **íŒŒì¼ëª…** | `{data_summary.get('file_name', 'N/A')}` |
| **íƒì§€ ì‹œê°„** | {data_summary.get('detected_at', 'N/A')} |
| **ìœ„í—˜ë„** | {data_summary.get('risk_level', 'N/A')} |
| **í˜„ì¬ ìƒíƒœ** | {data_summary.get('status', 'N/A')} |
| **ë‹´ë‹¹ì** | {data_summary.get('assigned_to', 'N/A')} |

---

## ğŸ” 2. ìœ„í˜‘ ë¶„ì„

### 2.1 ì•…ì„±ì½”ë“œ ë¶„ì„ ê²°ê³¼
- **íƒì§€ í™•ë¥ :** X%
- **ë¶„ë¥˜:** ëœì„¬ì›¨ì–´ / ê¸°íƒ€ ì•…ì„±ì½”ë“œ
- **ìœ„í˜‘ ë“±ê¸‰:** Critical / High / Medium / Low

### 2.2 ì´ìƒ ì§•í›„ (Anomalies)
*[íƒì§€ëœ ì´ìƒ íŠ¹ì„± ë‚˜ì—´ ë° í•´ì„]*

### 2.3 IOC (Indicators of Compromise)
*[íŒŒì¼ í•´ì‹œ, íŒŒì¼ëª… íŒ¨í„´, í–‰ìœ„ íŠ¹ì„± ë“±]*

### 2.4 ìœ ì‚¬ ì‚¬ë¡€ ë¶„ì„
*[ê³¼ê±° ìœ ì‚¬ ì‚¬ê³ , ì•Œë ¤ì§„ ìº í˜ì¸ê³¼ì˜ ì—°ê´€ì„±]*

---

## ğŸ“ 3. ì˜í–¥ ë²”ìœ„ í‰ê°€

### 3.1 ì§ì ‘ ì˜í–¥
*[ê°ì—¼ëœ ì‹œìŠ¤í…œ, íŒŒì¼ ëª©ë¡]*

### 3.2 ì ì¬ì  ì˜í–¥
*[í™•ì‚° ê°€ëŠ¥ì„±, 2ì°¨ í”¼í•´ ìš°ë ¤]*

### 3.3 ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸
*[ì—…ë¬´ ì¤‘ë‹¨, ë°ì´í„° ìœ ì¶œ, ì¬ì •ì  ì˜í–¥]*

---

## âš¡ 4. ëŒ€ì‘ ì¡°ì¹˜ íƒ€ì„ë¼ì¸

### 4.1 Preparation (ì‚¬ì „ ì¤€ë¹„)
- [íƒ€ì„ìŠ¤íƒ¬í”„] ë³´ì•ˆ ì‹œìŠ¤í…œ ì •ìƒ ê°€ë™ í™•ì¸

### 4.2 Detection & Analysis (íƒì§€ ë° ë¶„ì„)
- [íƒ€ì„ìŠ¤íƒ¬í”„] ëœì„¬ì›¨ì–´ ì˜ì‹¬ íŒŒì¼ íƒì§€
- [íƒ€ì„ìŠ¤íƒ¬í”„] ì´ˆê¸° ë¶„ì„ ì™„ë£Œ

### 4.3 Containment (ê²©ë¦¬)
- [íƒ€ì„ìŠ¤íƒ¬í”„] ì˜ì‹¬ íŒŒì¼ ê²©ë¦¬ ì¡°ì¹˜
- [íƒ€ì„ìŠ¤íƒ¬í”„] ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨ (í•„ìš”ì‹œ)

### 4.4 Eradication (ì œê±°)
- [íƒ€ì„ìŠ¤íƒ¬í”„] ì•…ì„±ì½”ë“œ ì™„ì „ ì œê±°

### 4.5 Recovery (ë³µêµ¬)
- [íƒ€ì„ìŠ¤íƒ¬í”„] ì‹œìŠ¤í…œ ë³µêµ¬ ì ˆì°¨ ì§„í–‰
- [íƒ€ì„ìŠ¤íƒ¬í”„] ì •ìƒ ìš´ì˜ ì¬ê°œ

### 4.6 Lessons Learned (êµí›ˆ ë„ì¶œ)
- [ì˜ˆì •] ì‚¬í›„ ê²€í†  íšŒì˜ ì¼ì •

---

## âœ… 5. ì™„ë£Œëœ ì¡°ì¹˜ì‚¬í•­
*[ì²´í¬ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì™„ë£Œëœ ëŒ€ì‘ ë‹¨ê³„ ì •ë¦¬]*

---

## ğŸ¯ 6. í–¥í›„ ì¡°ì¹˜ ê³„íš

### 6.1 ì¦‰ì‹œ ì¡°ì¹˜ (24ì‹œê°„ ì´ë‚´)
*[ê¸´ê¸‰ ëŒ€ì‘ ì‚¬í•­]*

### 6.2 ë‹¨ê¸° ì¡°ì¹˜ (1ì£¼ì¼ ì´ë‚´)
*[ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ê¸´ê¸‰ íŒ¨ì¹˜]*

### 6.3 ì¤‘ê¸° ê°œì„  (1ê°œì›” ì´ë‚´)
*[ì‹œìŠ¤í…œ/ì •ì±… ê°•í™” ê³„íš]*

---

## ğŸ” 7. ì¬ë°œ ë°©ì§€ ê¶Œê³ ì‚¬í•­

### 7.1 ê¸°ìˆ ì  í†µì œ
*[ë°©í™”ë²½, EDR, ë°±ì—… ë“±]*

### 7.2 ê´€ë¦¬ì  í†µì œ
*[ì •ì±…, ì ˆì°¨, ê¶Œí•œ ê´€ë¦¬]*

### 7.3 ì‚¬ìš©ì êµìœ¡
*[ë³´ì•ˆ ì¸ì‹ ì œê³  ë°©ì•ˆ]*

---

## ğŸ“Œ 8. ë²•ì /ê·œì œì  ê³ ë ¤ì‚¬í•­
*[ê°œì¸ì •ë³´ ìœ ì¶œ ì—¬ë¶€, ì‹ ê³  ì˜ë¬´, ê·œì œ ëŒ€ì‘]*

---

## ğŸ“Œ 9. ì¢…í•© ì˜ê²¬ ë° ê¶Œê³ 
*[CSIRT íŒ€ì¥ ì˜ê²¬, ê²½ì˜ì§„ ë³´ê³ ì‚¬í•­, í–¥í›„ ëŒ€ì‘ ë°©í–¥]*

---

**ë³´ê³ ì„œ ì¢…ë£Œ**
*ë³¸ ì‚¬ê³ ëŠ” [í•´ê²°/ì§„í–‰ì¤‘] ìƒíƒœì´ë©°, ì¶”ê°€ ì—…ë°ì´íŠ¸ ì‹œ ë³¸ ë³´ê³ ì„œê°€ ê°±ì‹ ë©ë‹ˆë‹¤.*
"""
    }

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # GPT-4o Mini ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  íš¨ìœ¨ì )
            messages=[
                {"role": "system", "content": system_prompts.get(report_type, system_prompts['daily'])},
                {"role": "user", "content": user_prompts.get(report_type, user_prompts['daily'])}
            ],
            temperature=0.7,  # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
            max_tokens=4000,  # ê¸´ ë³´ê³ ì„œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ í† í°
            top_p=0.9,
            frequency_penalty=0.3,  # ë°˜ë³µ ê°ì†Œ
            presence_penalty=0.3   # ë‹¤ì–‘í•œ í‘œí˜„ ì¥ë ¤
        )

        return response.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ AI ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nê¸°ë³¸ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."

# --- 13. ë³´ê³ ì„œ ìƒì„± ì‹œìŠ¤í…œ (AI ê°•í™” ë²„ì „) ---
def generate_daily_report(target_date=None, use_ai=True):
    """ì¼ê°„ ë³´ê³ ì„œ ìƒì„± (AI ê¸°ë°˜)"""
    if target_date is None:
        target_date = datetime.now().date()
    else:
        target_date = datetime.fromisoformat(target_date).date() if isinstance(target_date, str) else target_date

    date_str = target_date.strftime('%Y-%m-%d')
    report_dir = REPORTS_DIR / "daily" / date_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ë‚ ì§œì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['date'] = df['timestamp'].dt.date
    daily_df = df[df['date'] == target_date]

    if daily_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(daily_df)
    ransomware_count = int((daily_df['label'] == 1).sum())
    benign_count = int((daily_df['label'] == 0).sum())
    avg_prob = float(daily_df['probability'].mean()) if 'probability' in daily_df.columns else 0.0

    # ì‹œê°„ëŒ€ë³„ í†µê³„
    hourly_stats = daily_df.groupby(daily_df['timestamp'].dt.hour).size()
    hourly_data = {f"{int(hour):02d}:00": int(count) for hour, count in hourly_stats.items()}

    # ëœì„¬ì›¨ì–´ ìƒì„¸ ì •ë³´
    ransomware_details = []
    if ransomware_count > 0:
        ransomware_events = daily_df[daily_df['label'] == 1]
        for idx, row in ransomware_events.iterrows():
            ransomware_details.append({
                "file_name": row['file_name'],
                "file_path": str(row['file_path']),
                "detected_time": row['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                "probability": float(row.get('probability', 0)),
                "action": str(row.get('action_result', 'N/A'))
            })

    # AI ë³´ê³ ì„œ ìƒì„±ìš© ë°ì´í„° ìš”ì•½
    data_summary = {
        "date": date_str,
        "total_events": total_events,
        "ransomware_count": ransomware_count,
        "benign_count": benign_count,
        "avg_probability": avg_prob,
        "hourly_distribution": hourly_data,
        "ransomware_details": ransomware_details
    }

    # AIë¥¼ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±
    if use_ai:
        report_content = generate_ai_report('daily', data_summary)
    else:
        # ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš© (í´ë°±)
        report_content = f"""# ì¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ë‚ ì§œ:** {date_str}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ìš”ì•½
- ì´ íƒì§€: {total_events}ê±´
- ëœì„¬ì›¨ì–´: {ransomware_count}ê±´
- ì •ìƒ: {benign_count}ê±´
- í‰ê·  ìœ„í—˜ë„: {avg_prob:.2%}
"""

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"daily_report_{date_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_weekly_report(target_week=None, use_ai=True):
    """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± (AI ê¸°ë°˜)"""
    if target_week is None:
        today = datetime.now()
        week_num = today.isocalendar()[1]
        year = today.year
    else:
        year, week_num = map(int, target_week.split('-W'))

    week_str = f"{year}-W{week_num:02d}"
    report_dir = REPORTS_DIR / "weekly" / week_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ì£¼ì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['week'] = df['timestamp'].dt.isocalendar().week
    df['year'] = df['timestamp'].dt.year
    weekly_df = df[(df['year'] == year) & (df['week'] == week_num)]

    if weekly_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(weekly_df)
    ransomware_count = int((weekly_df['label'] == 1).sum())
    benign_count = int((weekly_df['label'] == 0).sum())
    avg_prob = float(weekly_df['probability'].mean()) if 'probability' in weekly_df.columns else 0.0

    # ì¼ë³„ í†µê³„
    daily_stats = weekly_df.groupby(weekly_df['timestamp'].dt.date).agg({
        'label': ['count', ('ransomware', lambda x: (x == 1).sum())]
    })

    daily_data = {}
    for date_val, row in daily_stats.iterrows():
        daily_data[str(date_val)] = {
            "total": int(row[('label', 'count')]),
            "ransomware": int(row[('label', 'ransomware')]),
            "benign": int(row[('label', 'count')] - row[('label', 'ransomware')])
        }

    # Top íŒŒì¼ í†µê³„
    top_files = []
    if ransomware_count > 0:
        ransomware_events = weekly_df[weekly_df['label'] == 1]
        file_counts = ransomware_events['file_name'].value_counts()
        top_files = [{"file_name": str(name), "count": int(count)} for name, count in file_counts.head(5).items()]

    # AI ë³´ê³ ì„œ ìƒì„±ìš© ë°ì´í„° ìš”ì•½
    data_summary = {
        "period": f"{year}ë…„ {week_num}ì£¼ì°¨",
        "week_string": week_str,
        "total_events": total_events,
        "ransomware_count": ransomware_count,
        "benign_count": benign_count,
        "avg_probability": avg_prob,
        "daily_average": round(total_events / 7, 1),
        "daily_stats": daily_data,
        "top_files": top_files
    }

    # AIë¥¼ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±
    if use_ai:
        report_content = generate_ai_report('weekly', data_summary)
    else:
        # ê¸°ë³¸ í…œí”Œë¦¿
        report_content = f"""# ì£¼ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {week_str}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ìš”ì•½
- ì´ íƒì§€: {total_events}ê±´
- ëœì„¬ì›¨ì–´: {ransomware_count}ê±´
"""

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"weekly_report_{week_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_monthly_report(target_month=None, use_ai=True):
    """ì›”ê°„ ë³´ê³ ì„œ ìƒì„± (AI ê¸°ë°˜)"""
    if target_month is None:
        today = datetime.now()
        year = today.year
        month = today.month
    else:
        year, month = map(int, target_month.split('-'))

    month_str = f"{year}-{month:02d}"
    report_dir = REPORTS_DIR / "monthly" / month_str
    os.makedirs(report_dir, exist_ok=True)

    df = load_events_log()
    if df.empty:
        return None

    # í•´ë‹¹ ì›”ì˜ ì´ë²¤íŠ¸ í•„í„°ë§
    df['month'] = df['timestamp'].dt.to_period('M')
    target_period = pd.Period(f"{year}-{month:02d}", freq='M')
    monthly_df = df[df['month'] == target_period]

    if monthly_df.empty:
        return None

    # í†µê³„ ê³„ì‚°
    total_events = len(monthly_df)
    ransomware_count = int((monthly_df['label'] == 1).sum())
    benign_count = int((monthly_df['label'] == 0).sum())
    avg_prob = float(monthly_df['probability'].mean()) if 'probability' in monthly_df.columns else 0.0

    # ì£¼ë³„ í†µê³„
    weekly_stats = monthly_df.groupby(monthly_df['timestamp'].dt.isocalendar().week).agg({
        'label': ['count', ('ransomware', lambda x: (x == 1).sum())]
    })

    weekly_data = {}
    for week, row in weekly_stats.iterrows():
        weekly_data[f"{int(week)}ì£¼ì°¨"] = {
            "total": int(row[('label', 'count')]),
            "ransomware": int(row[('label', 'ransomware')]),
            "benign": int(row[('label', 'count')] - row[('label', 'ransomware')])
        }

    # Top íŒŒì¼ ë° ì‹œê°„ëŒ€ ë¶„ì„
    top_files = []
    peak_hour = None
    if ransomware_count > 0:
        ransomware_events = monthly_df[monthly_df['label'] == 1]
        file_counts = ransomware_events['file_name'].value_counts()
        top_files = [{"file_name": str(name), "count": int(count)} for name, count in file_counts.head(10).items()]

        hourly_distribution = ransomware_events.groupby(ransomware_events['timestamp'].dt.hour).size()
        peak_hour = int(hourly_distribution.idxmax())

    # AI ë³´ê³ ì„œ ìƒì„±ìš© ë°ì´í„° ìš”ì•½
    data_summary = {
        "period": f"{year}ë…„ {month}ì›”",
        "month_string": month_str,
        "total_events": total_events,
        "ransomware_count": ransomware_count,
        "benign_count": benign_count,
        "avg_probability": avg_prob,
        "daily_average": round(total_events / 30, 1),
        "weekly_stats": weekly_data,
        "top_files": top_files,
        "peak_hour": peak_hour
    }

    # AIë¥¼ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±
    if use_ai:
        report_content = generate_ai_report('monthly', data_summary)
    else:
        # ê¸°ë³¸ í…œí”Œë¦¿
        report_content = f"""# ì›”ê°„ ë³´ì•ˆ ê´€ì œ ë³´ê³ ì„œ
**ê¸°ê°„:** {month_str}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ìš”ì•½
- ì´ íƒì§€: {total_events}ê±´
- ëœì„¬ì›¨ì–´: {ransomware_count}ê±´
"""

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / f"monthly_report_{month_str}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    return report_path

def generate_incident_report(incident):
    """ì‚¬ê³  ë³´ê³ ì„œ ìƒì„± (AI ê¸°ë°˜)"""
    incident_id = incident['incident_id']
    file_name_safe = incident['file_name'].replace('/', '_').replace('\\', '_')
    report_dir = REPORTS_DIR / "incidents" / f"{incident_id}_{file_name_safe}"
    os.makedirs(report_dir, exist_ok=True)

    # ì‚¬ê³  ë°ì´í„° ìš”ì•½ ì¤€ë¹„
    data_summary = {
        'incident_id': incident_id,
        'file_name': incident['file_name'],
        'file_path': incident['file_path'],
        'detected_at': incident['created_at'],
        'probability': f"{incident['probability']:.2%}",
        'priority': incident['priority'],
        'assigned_to': incident['assigned_to'],
        'status': incident['status'],
        'timeline': incident['timeline'],
        'checklist': incident['checklist'],
        'risk_level': 'ê³ ìœ„í—˜' if incident['probability'] >= 0.8 else 'ì¤‘ìœ„í—˜' if incident['probability'] >= 0.5 else 'ì €ìœ„í—˜'
    }

    # AIë¡œ ë³´ê³ ì„œ ìƒì„±
    try:
        ai_report = generate_ai_report('incident', data_summary)
        report_content = ai_report

        # AI ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        if not ai_report or "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in ai_report or "ì˜¤ë¥˜" in ai_report:
            raise Exception("AI ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        st.warning(f"âš ï¸ AI ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}\nê¸°ë³¸ í…œí”Œë¦¿ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")

        report_content = f"""# ëœì„¬ì›¨ì–´ ì‚¬ê³  ëŒ€ì‘ ë³´ê³ ì„œ
**ì‚¬ê³  ID:** {incident_id}
**ìƒì„± ì‹œê°„:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## 1. ì‚¬ê³  ê°œìš”

- **íŒŒì¼ëª…:** `{incident['file_name']}`
- **íŒŒì¼ ê²½ë¡œ:** `{incident['file_path']}`
- **íƒì§€ ì‹œê°„:** {incident['created_at']}
- **ëœì„¬ì›¨ì–´ í™•ë¥ :** {incident['probability']:.2%}
- **ìš°ì„ ìˆœìœ„:** {incident['priority']}
- **ë‹´ë‹¹ì:** {incident['assigned_to']}
- **í˜„ì¬ ìƒíƒœ:** {incident['status']}

---

## 2. ì‚¬ê³  íƒ€ì„ë¼ì¸

"""
        for event in incident['timeline']:
            timestamp = datetime.fromisoformat(event['timestamp']).strftime('%Y-%m-%d %H:%M:%S')
            report_content += f"### {timestamp} - {event['status']}\n{event['description']}\n\n"

        report_content += "---\n\n## 3. ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸\n\n"

        for task in incident['checklist']:
            status = "âœ… ì™„ë£Œ" if task['completed'] else "â¬œ ë¯¸ì™„ë£Œ"
            report_content += f"- {status}: {task['task']}\n"

        report_content += "\n---\n\n## 4. ì¡°ì¹˜ ì‚¬í•­\n\n"

        if incident['status'] == 'ì™„ë£Œ':
            report_content += "ëª¨ë“  ëŒ€ì‘ ì ˆì°¨ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        else:
            report_content += f"í˜„ì¬ '{incident['status']}' ìƒíƒœë¡œ ëŒ€ì‘ì´ ì§„í–‰ì¤‘ì…ë‹ˆë‹¤.\n"

        report_content += "\n---\n\n**ë³´ê³ ì„œ ì¢…ë£Œ**"

    # íŒŒì¼ ì €ì¥
    report_path = report_dir / "incident_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    # JSON ìƒì„¸ ë°ì´í„° ì €ì¥
    json_path = report_dir / "analysis_details.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(incident, f, ensure_ascii=False, indent=2)

    return report_path

# --- 13. í˜ì´ì§€ 3: ë³´ê³ ì„œ ì‘ì„± ---
def render_report_generation():
    """í˜ì´ì§€ 3: ë³´ê³ ì„œ ì‘ì„±"""
    st.header("ğŸ“ ë³´ê³ ì„œ ì‘ì„±")
    st.markdown("---")

    st.subheader("ğŸ“… ì •ê¸° ë³´ê³ ì„œ ìƒì„±")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("### ì¼ê°„ ë³´ê³ ì„œ")
        date_input = st.date_input("ë‚ ì§œ ì„ íƒ", value=datetime.now().date())

        if st.button("ì¼ê°„ ë³´ê³ ì„œ ìƒì„±", key="daily_btn"):
            with st.spinner("ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_daily_report(date_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        st.markdown("### ì£¼ê°„ ë³´ê³ ì„œ")
        week_input = st.text_input("ì£¼ì°¨ ì„ íƒ (ì˜ˆ: 2025-W47)", value=f"{datetime.now().year}-W{datetime.now().isocalendar()[1]:02d}")

        if st.button("ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±", key="weekly_btn"):
            with st.spinner("ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_weekly_report(week_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ì£¼ì°¨ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col3:
        st.markdown("### ì›”ê°„ ë³´ê³ ì„œ")
        month_input = st.text_input("ì›” ì„ íƒ (ì˜ˆ: 2025-11)", value=f"{datetime.now().year}-{datetime.now().month:02d}")

        if st.button("ì›”ê°„ ë³´ê³ ì„œ ìƒì„±", key="monthly_btn"):
            with st.spinner("ì›”ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_monthly_report(month_input)
                if report_path:
                    st.success(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                    st.code(str(report_path))

                    # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                    with open(report_path, 'r', encoding='utf-8') as f:
                        st.markdown(f.read())
                else:
                    st.warning("í•´ë‹¹ ì›”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±
    st.subheader("ğŸš¨ ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±")

    incidents = load_incidents()
    if incidents:
        incident_options = {f"{inc['incident_id']} - {inc['file_name']}": inc for inc in incidents}
        selected_incident_key = st.selectbox("ì‚¬ê³  ì„ íƒ", list(incident_options.keys()))

        if st.button("ì‚¬ê³  ë³´ê³ ì„œ ìƒì„±", key="incident_btn"):
            selected_incident = incident_options[selected_incident_key]
            with st.spinner("ì‚¬ê³  ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                report_path = generate_incident_report(selected_incident)
                st.success(f"âœ… ì‚¬ê³  ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                st.code(str(report_path))

                # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°
                with open(report_path, 'r', encoding='utf-8') as f:
                    st.markdown(f.read())
    else:
        st.info("ìƒì„±í•  ì‚¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ í‘œì‹œ
    st.subheader("ğŸ“‚ ë³´ê³ ì„œ ë””ë ‰í† ë¦¬ êµ¬ì¡°")

    if st.button("ë””ë ‰í† ë¦¬ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    # ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ ìƒì„±
    tree_structure = ""
    for root, dirs, files in os.walk(REPORTS_DIR):
        level = root.replace(str(REPORTS_DIR), '').count(os.sep)
        indent = ' ' * 2 * level
        tree_structure += f"{indent}{os.path.basename(root)}/\n"
        sub_indent = ' ' * 2 * (level + 1)
        for file in files:
            tree_structure += f"{sub_indent}{file}\n"

    st.code(tree_structure, language="")


# --- 12. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
ransomware_model = load_ransomware_model()

if "page" not in st.session_state:
    st.session_state.page = "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ"

with st.sidebar:
    st.title("ğŸ›¡ï¸ V4 í†µí•© ë³´ì•ˆ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    page_options = {
        "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ": "ğŸ“¡",
        "ì‚¬ê³  ëŒ€ì‘": "ğŸš¨",
        "ë³´ê³ ì„œ ì‘ì„±": "ğŸ“"
    }

    choice = st.radio(
        "ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(page_options.keys()),
        format_func=lambda x: f"{page_options[x]} {x}"
    )

    if choice != st.session_state.page:
        st.session_state.page = choice
        st.rerun()

    st.markdown("---")
    if ransomware_model:
        st.success("**ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„:** âœ… ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.error("**ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„:** âŒ ë¡œë“œ ì‹¤íŒ¨")
    st.markdown("---")

# í˜ì´ì§€ ë Œë”ë§
if st.session_state.page == "ì‹¤ì‹œê°„ ë³´ì•ˆ ê´€ì œ":
    if ransomware_model:
        render_realtime_soc_dashboard()
    else:
        st.error("ëœì„¬ì›¨ì–´ ë¶„ì„ ì—”ì§„ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì´ í˜ì´ì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
elif st.session_state.page == "ì‚¬ê³  ëŒ€ì‘":
    render_incident_response()
elif st.session_state.page == "ë³´ê³ ì„œ ì‘ì„±":
    render_report_generation()
