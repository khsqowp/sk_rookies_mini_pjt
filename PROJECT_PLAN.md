# 프로젝트 계획: AI 기반 랜섬웨어 탐지 및 분석 대시보드

## 1. 프로젝트 개요

### 1.1. 프로젝트 명
AI 기반 랜섬웨어 패턴 분석 및 탐지 대시보드

### 1.2. 프로젝트 목표 (KPI)
- **데이터 벡터화**: 랜섬웨어 관련 CSV(UNSW-NB15) 데이터의 핵심 피처를 전처리하고 FAISS 벡터 DB에 저장하여 유사도 검색 기반을 구축한다.
- **탐지 모델 구현**: 사용자가 업로드한 로그 파일을 벡터 DB 및 OpenAI LLM과 비교 분석하여 랜섬웨어 패턴 유무를 판별하는 탐지 시스템을 개발한다.
- **대시보드 시각화**: 탐지 결과를 Streamlit 대시보드에 표시하고, 공격 유형별 탐지 횟수를 차트로 시각화하여 직관적인 분석 환경을 제공한다.

### 1.3. 핵심 페르소나 (Agent Persona)
LLM 모델은 **"랜섬웨어 공격 패턴 분석에 특화된 AI 보안 전문가"**의 페르소나를 갖는다. 분석 요청된 데이터에 대해 기존 벡터 DB의 패턴과 비교하여 랜섬웨어 공격 가능성을 판단하고, 그 근거를 명확하게 설명한다.

### 1.4. 핵심 기술 스택
- **AI/LLM**: LangChain, OpenAI API
- **데이터 처리/분석**: Pandas, Numpy
- **벡터 DB**: FAISS-cpu, langchain-community
- **웹/시각화**: Streamlit
- **환경/보안**: python-dotenv

## 2. 시스템 아키텍처 및 데이터 흐름

1.  **데이터 준비 (CSV 전처리 및 벡터화)**
    - `vector_db_builder.py` 스크립트가 `Mini_PJT2/CSV Files/` 디렉토리의 랜섬웨어 관련 CSV 파일을 로드한다.
    - **전처리**: Pandas를 사용하여 데이터셋을 분석하고, 랜섬웨어 탐지에 유의미한 핵심 피처(예: `sttl`, `dttl`, `sload`, `dload`, `ct_state_ttl` 등)를 식별 및 추출한다.
    - **벡터화**: 추출된 핵심 피처 데이터를 기반으로 텍스트 임베딩을 생성하고, FAISS 벡터 데이터베이스를 구축하여 로컬(`vector_db/`)에 저장한다.

2.  **대시보드 실행 및 분석 (Dashboard)**
    - `dashboard.py`를 통해 Streamlit 대시보드를 실행한다.
    - **파일 업로드**: 사용자는 분석을 원하는 로그 파일(CSV 형식)을 대시보드에 업로드한다.
    - **유사도 검색**: 시스템은 업로드된 파일의 데이터를 벡터화하여 FAISS DB에서 가장 유사한 공격 패턴을 검색(Similarity Search)한다.
    - **LLM 분석 및 판별**: 검색된 유사 패턴과 업로드된 파일 데이터를 컨텍스트로 구성하여 OpenAI LLM에게 전달한다. LLM은 이를 바탕으로 해당 파일이 랜섬웨어 공격 패턴을 포함하는지 여부를 최종 판별하고 분석 리포트를 생성한다.
    - **결과 표시 및 저장**: 분석 결과(랜섬웨어 여부, 분석 리포트)를 대시보드에 표시하고, 탐지 로그를 별도의 파일로 저장한다.
    - **차트 업데이트**: 탐지된 공격을 `attack_cat` (공격 유형) 기준으로 집계하여 "공격 유형별 랜섬웨어 탐지 횟수" 차트를 동적으로 업데이트한다.

## 3. 핵심 기능 명세

### 3.1. F-1: 데이터 전처리 및 벡터 DB 구축 (`vector_db_builder.py`)
- **요구사항**: UNSW-NB15 데이터셋의 특성을 파악하고 랜섬웨어 탐지에 유의미한 피처를 선정하여 벡터화한다.
- **세부 기능**:
    - `Mini_PJT2/CSV Files/` 내의 모든 CSV 파일을 Pandas DataFrame으로 로드.
    - 데이터의 통계적 특성을 분석하여 랜섬웨어 탐지와 연관성이 높은 숫자 및 범주형 피처를 선택.
    - 선택된 피처들을 텍스트 형태로 조합하여 LangChain `Document` 객체를 생성.
    - 생성된 Document를 임베딩하여 FAISS 인덱스를 구축하고 `vector_db/faiss_index`에 저장.

### 3.2. F-2: 랜섬웨어 탐지 분석기 (`log_analyzer.py`)
- **요구사항**: 업로드된 데이터를 기반으로 벡터 DB와 LLM을 연동하여 랜섬웨어 여부를 판별한다.
- **세부 기능**:
    - 업로드된 CSV 파일을 DataFrame으로 로드하고, DB에 저장된 것과 동일한 방식으로 피처를 추출/조합.
    - FAISS DB에 `similarity_search`를 수행하여 가장 유사한 과거 공격 패턴 문서를 검색.
    - 검색된 문서와 현재 데이터를 바탕으로 OpenAI LLM에 전달할 프롬프트를 동적으로 생성.
    - LLM의 답변(랜섬웨어 여부, 근거)을 구조화된 형식으로 파싱하여 반환.

### 3.3. F-3: 인터랙티브 분석 대시보드 (`dashboard.py`)
- **요구사항**: 사용자가 파일을 쉽게 업로드하고, 분석 결과를 명확하게 인지하며, 탐지 통계를 시각적으로 확인할 수 있는 UI를 제공한다.
- **세부 기능**:
    - `st.file_uploader`를 사용하여 사용자로부터 CSV 파일 입력을 받음.
    - '분석 실행' 버튼 클릭 시, `log_analyzer.py`의 분석 함수를 호출하고 스피너(spinner)로 진행 상태를 표시.
    - 분석 완료 후, `st.success` 또는 `st.error`를 통해 랜섬웨어 여부를 명확히 표시.
    - LLM이 생성한 상세 분석 리포트를 `st.expander` 내에 표시.
    - 탐지 결과를 별도의 로그 파일(JSON 형식)에 저장.
    - 저장된 모든 탐지 로그를 읽어와 `attack_cat`별로 횟수를 집계하고, `st.bar_chart`를 통해 시각화.

## 4. 최종 산출물 (파일 목록)

- `PROJECT_PLAN.md` (현재 문서)
- `vector_db_builder.py` (FAISS 인덱스 생성기)
- `log_analyzer.py` (랜섬웨어 탐지 및 LLM 분석 로직)
- `dashboard.py` (Streamlit 메인 대시보드)
- `requirements.txt` (필요 라이브러리 목록)
- `.gitignore` (버전 관리 제외 파일 목록)
- `run_dashboard.sh` (대시보드 실행 스크립트)
- `.env` (API 키 등 환경 변수 저장)
- `output_analysis/` (탐지 결과 로그 저장 디렉토리)
- `vector_db/` (FAISS 인덱스 저장 디렉토리)
